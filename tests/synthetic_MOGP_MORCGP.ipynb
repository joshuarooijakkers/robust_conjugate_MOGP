{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor, MORCGPRegressor, MOGPRegressor_NC, MORCGPRegressor_NC, MORCGPRegressor_NC_fixed_weights, MORCGPRegressor_fixed_weights, MORCGPRegressor_PM\n",
    "from rcgp.rcgp import RCGPRegressor\n",
    "from rcgp.kernels import ConstantMean, RBFKernel, SineMean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 28,         \n",
    "    'axes.labelsize': 28,    \n",
    "    'axes.titlesize': 30,    \n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 24,\n",
    "    'lines.linewidth': 5,    \n",
    "    'lines.markersize': 6   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_overlap(y_train, overlap_ratio):\n",
    "    N, D = y_train.shape\n",
    "    indices = np.arange(N)\n",
    "\n",
    "    n_overlap = int(overlap_ratio * N)\n",
    "\n",
    "    shared_indices = np.random.choice(indices, size=n_overlap, replace=False)\n",
    "\n",
    "    y_obs = np.full_like(y_train, np.nan)\n",
    "\n",
    "    y_obs[shared_indices, :] = y_train[shared_indices, :]\n",
    "\n",
    "    remaining_indices = np.setdiff1d(indices, shared_indices)\n",
    "\n",
    "    n_unique_per_output = (N - n_overlap) // D\n",
    "\n",
    "    for d in range(D):\n",
    "        if d < D - 1:\n",
    "            chosen = np.random.choice(remaining_indices, size=n_unique_per_output, replace=False)\n",
    "            remaining_indices = np.setdiff1d(remaining_indices, chosen)\n",
    "        else:\n",
    "            chosen = remaining_indices\n",
    "        y_obs[chosen, d] = y_train[chosen, d]\n",
    "\n",
    "    return y_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b00af",
   "metadata": {},
   "source": [
    "## MOGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43460f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Initialisation\n",
    "constant_mean = 0\n",
    "length_scale = 0.1\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 100\n",
    "overlap_ratio = 0.9\n",
    "\n",
    "A = np.array([[1, 0], \n",
    "              [0.9, 0.436]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "# noise = np.array([0.01, 0.16])\n",
    "noise = np.array([0.04, 0.09])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.linspace(0, 1, n_points).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "y_train = apply_overlap(y_train, overlap_ratio)\n",
    "\n",
    "# indices_025 = np.where((x_train >= 0.20) & (x_train <= 0.30))[0]\n",
    "# outlier_indices_025 = np.random.choice(indices_025, 1, replace=False)\n",
    "# y_train[outlier_indices_025, 0] = -5\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Output {i+1}')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "mogp = MOGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "mogp.fit(x_train, y_train)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "# mogp.optimize_loo_cv(print_opt_param=True, print_iter_param=True)\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu, var = mogp.predict(x_test)\n",
    "std = np.sqrt(var + mogp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0ba24",
   "metadata": {},
   "source": [
    "## Original IMQ - MORCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# Initialisation\n",
    "constant_mean = 0\n",
    "length_scale = 0.1\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 100\n",
    "overlap_ratio = 0.9\n",
    "epsilons = np.array([0.05, 0])\n",
    "\n",
    "noise_variance = 0.04\n",
    "\n",
    "A = np.array([[1.414, 0], \n",
    "    [0.849, 0.529]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "# noise = np.array([0.01, 0.16])\n",
    "noise = np.array([0.04, 0.04])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.linspace(0, 1, n_points).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "y_train = apply_overlap(y_train, overlap_ratio)\n",
    "\n",
    "indices_025 = np.where((x_train >= 0.40) & (x_train <= 0.50))[0]\n",
    "outlier_indices_025 = np.random.choice(indices_025, int(epsilons[0] * n_points), replace=False)\n",
    "y_train[outlier_indices_025, 0] = 2\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Output {i+1}')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b463ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp = MORCGPRegressor_PM(mean = 0, length_scale=0.1, noise = noise, A=A, epsilons=epsilons)\n",
    "# morcgp = MORCGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "morcgp.fit(x_train, y_train)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=0.1, noise=0.04, A=A, weighted=True, B_weighted=B))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=True)\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu, var = morcgp.predict(x_test)\n",
    "std = np.sqrt(var + morcgp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e1c88",
   "metadata": {},
   "source": [
    "## MORCGP - cross channel predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fe8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# Initialisation\n",
    "constant_mean = 0\n",
    "length_scale = 0.1\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 100\n",
    "overlap_ratio = 0.9\n",
    "\n",
    "noise_variance = 0.04\n",
    "\n",
    "A = np.array([[1.414, 0], \n",
    "    [0.849, 0.529]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "# noise = np.array([0.01, 0.16])\n",
    "noise = np.array([0.04, 0.04])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.linspace(0, 1, n_points).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "y_train = apply_overlap(y_train, overlap_ratio)\n",
    "\n",
    "indices_025 = np.where((x_train >= 0.40) & (x_train <= 0.50))[0]\n",
    "outlier_indices_025 = np.random.choice(indices_025, int(4), replace=False)\n",
    "y_train[outlier_indices_025, 0] = 2\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Output {i+1}')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train\n",
    "mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "mogp.fit(x_train, y_train)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_B = mogp.B\n",
    "optim_noise = mogp.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train\n",
    "morcgp = MORCGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "# morcgp = MORCGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "predictive_mean, predictive_variances = morcgp.fit(x_train, y_train)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=0.1, noise=0.04, A=A, weighted=True, B_weighted=B))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=True, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "predictive_mean, predictive_variances = morcgp.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu, var = morcgp.predict(x_test)\n",
    "std = np.sqrt(var + morcgp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "\n",
    "    axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "\n",
    "    # axs[i].plot(x_train.flatten(), ((morcgp.weights_01.reshape(n_outputs,-1).T))[:,i], '_', color='red', label=f'Predictive Mean', markersize=10)\n",
    "\n",
    "    # axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    # axs[i].fill_between(x_test.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48154be",
   "metadata": {},
   "source": [
    "## Fixed weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# Initialisation\n",
    "constant_mean = 0\n",
    "length_scale = 0.1\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 100\n",
    "overlap_ratio = 0.9\n",
    "\n",
    "noise_variance = 0.04\n",
    "\n",
    "A = np.array([[1.414, 0], \n",
    "    [0.849, 0.529]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "# noise = np.array([0.01, 0.16])\n",
    "noise = np.array([0.04, 0.04])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.linspace(0, 1, n_points).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "y_train = apply_overlap(y_train, overlap_ratio)\n",
    "\n",
    "indices_025 = np.where((x_train >= 0.40) & (x_train <= 0.50))[0]\n",
    "outlier_indices_025 = np.random.choice(indices_025, int(4), replace=False)\n",
    "y_train[outlier_indices_025, 0] = 2\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Output {i+1}')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mogp = MOGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "mogp.fit(x_train, y_train)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_length_scale = mogp.length_scale\n",
    "optim_A = mogp.A\n",
    "optim_B = mogp.B\n",
    "optim_noise = mogp.noise\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu, var = mogp.predict(x_test)\n",
    "std = np.sqrt(var + mogp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92681728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=A)\n",
    "morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=optim_A)\n",
    "predictive_mean, predictive_variances = morcgp.fit(x_train, y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=0.1, noise=0.04, A=A, weighted=True, B_weighted=B))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=True)\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu, var = morcgp.predict(x_test)\n",
    "std = np.sqrt(var + morcgp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "\n",
    "    axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f36b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'k*', label=f'Observed Data')\n",
    "\n",
    "    # axs[i].plot(x_train.flatten(), ((morcgp.w01.reshape(2,-1).T))[:,i], '_', color='red', label=f'Predictive Mean', markersize=10)\n",
    "\n",
    "    # axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    # axs[i].fill_between(x_test.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88118a",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aedb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(48)\n",
    "# Initialisation\n",
    "epsilon = 0.05\n",
    "constant_mean = 0\n",
    "length_scale = 0.2\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 160\n",
    "overlap_ratio = 1\n",
    "\n",
    "A = np.array([[1.414, 0], \n",
    "    [0.849, 0.529]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "noise1 = 0.05\n",
    "noise2 = 0.05\n",
    "noise = np.array([noise1, noise2])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.sort(np.random.uniform(0, 1, n_points)).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "outlier_range = np.where((x_train >= 0.48) & (x_train <= 0.6))[0]\n",
    "outlier_indices = np.random.choice(outlier_range, int(epsilon*n_points), replace=False)\n",
    "y_train[outlier_indices, 0] = np.random.normal(loc=-3, scale=0.5, size=outlier_indices.shape[0])\n",
    "\n",
    "mask = np.ones(len(x_train), dtype=bool)\n",
    "mask[outlier_indices] = False\n",
    "\n",
    "y_train -= np.mean(y_train, axis=0)\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        axs[i].plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', label='Outlier points')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-5, 5])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "# mogp = MOGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "mogp.fit(x_train, y_train)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_length_scale = mogp.length_scale\n",
    "optim_B = mogp.B\n",
    "optim_A = mogp.A\n",
    "optim_noise = mogp.noise\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "std_mogp = np.sqrt(var + mogp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', label=f'Observed Data')\n",
    "    axs[i].plot(x_test.flatten(), mu_mogp[:, i], '-', color='blue', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu_mogp[:, i] - 2*std_mogp[:, i], mu_mogp[:, i] + 2*std_mogp[:, i], color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# morcgp = MORCGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=optim_A)\n",
    "# predictive_mean, predictive_variances = morcgp.fit(x_train, y_train)\n",
    "\n",
    "morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=optim_A)\n",
    "# morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=optim_A)\n",
    "predictive_mean, predictive_variances = morcgp.fit(x_train, y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=length_scale, noise=np.array([0.05, 0.05]), A=A, weighted=True))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=True, \n",
    "                    #    B_weighted=optim_B, noise_weighted=optim_noise\n",
    "                       )\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "length_scale_morcgp = morcgp.length_scale\n",
    "A_morcgp = morcgp.A\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        axs[i].plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', label='Outlier points')\n",
    "\n",
    "    axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    axs[i].fill_between(x_train.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu_morcgp[:, i], '-', color='green', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu_morcgp[:, i] - 2*std_morcgp[:, i], mu_morcgp[:, i] + 2*std_morcgp[:, i], color='green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-7, 7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f66ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        axs[i].plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', label='Outlier points')\n",
    "\n",
    "    # axs[i].plot(x_train.flatten(), predictive_mean[:, i], '-', color='blue', label=f'Predictive Mean')\n",
    "    # axs[i].fill_between(x_train.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances[:, i]), predictive_mean[:, i] + np.sqrt(predictive_variances[:, i]), color='blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu_morcgp[:, i], '-', color='green', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu_morcgp[:, i] - 2*std_morcgp[:, i], mu_morcgp[:, i] + 2*std_morcgp[:, i], color='green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-9, 7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    axs[i].plot(x_train.flatten(), ((morcgp.w01.reshape(n_outputs,-1).T))[:,i], '_', color='red', label=f'Predictive Mean', markersize=10)\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae131fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1, y_train2 = y_train[:, 0].reshape(-1,1), y_train[:, 1].reshape(-1,1)\n",
    "\n",
    "mu_rcgp = np.full((len(x_test), 2), np.nan)\n",
    "std_rcgp = np.full((len(x_test), 2), np.nan)\n",
    "\n",
    "# Plot 1 ------------------\n",
    "\n",
    "constant_mean = ConstantMean(constant=0)\n",
    "rcgp1 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=noise1, epsilon=epsilon)\n",
    "rcgp1.fit(x_train, y_train1)\n",
    "rcgp1.optimize_loo_cv(weighted=False, print_opt_param=True)\n",
    "\n",
    "mu_rcgp[:, 0], var_rcgp = rcgp1.predict(x_test)\n",
    "std_rcgp[:, 0] = np.sqrt(var_rcgp + rcgp1.noise)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].plot(x_train[mask], y_train1[mask], 'o', color='black', alpha=0.5)\n",
    "axs[0].plot(x_train[~mask], y_train1[~mask], 'o', color='red')\n",
    "axs[0].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[0].plot(x_test, mu_rcgp[:, 0].ravel(), color=\"royalblue\")\n",
    "axs[0].fill_between(x_test.ravel(), mu_rcgp[:, 0].ravel() - 1.96 * std_rcgp[:, 0], mu_rcgp[:, 0].ravel() + 1.96 * std_rcgp[:, 0], alpha=0.3, color='royalblue')\n",
    "axs[0].set_ylim([-9, 7])\n",
    "\n",
    "# Plot 2 ------------------\n",
    "\n",
    "rcgp2 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=noise2, epsilon=epsilon)\n",
    "rcgp2.fit(x_train, y_train2)\n",
    "rcgp2.optimize_loo_cv(weighted=False, print_opt_param=True)\n",
    "\n",
    "mu_rcgp[:, 1], var2 = rcgp2.predict(x_test)\n",
    "std_rcgp[:, 1] = np.sqrt(var2 + rcgp2.noise)\n",
    "\n",
    "axs[1].plot(x_train[mask], y_train2[mask], 'o', color='black', alpha=0.5)\n",
    "# axs[1].plot(x_train[~mask], y_train2[~mask], 'o', color='red')\n",
    "axs[1].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[1].plot(x_test, mu_rcgp[:, 1].ravel(), color=\"royalblue\")\n",
    "axs[1].fill_between(x_test.ravel(), mu_rcgp[:, 1].ravel() - 1.96 * std_rcgp[:, 1], mu_rcgp[:, 1].ravel() + 1.96 * std_rcgp[:, 1], alpha=0.3, color='royalblue')\n",
    "axs[1].set_ylim([-9, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp = MORCGPRegressor_PM(mean = 0, length_scale=optim_length_scale, noise = noise, A=optim_A, epsilons=np.array([epsilon, 0]))\n",
    "morcgp.fit(x_train, y_train)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=0.1, noise=0.04, A=A, weighted=True, B_weighted=B))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=True, \n",
    "                    #    B_weighted=optim_B, noise_weighted=optim_noise\n",
    "                       )\n",
    "\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_pm, var_pm = morcgp.predict(x_test)\n",
    "std_pm = np.sqrt(var_pm + morcgp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        axs[i].plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', label='Outlier points')\n",
    "\n",
    "    axs[i].plot(x_test.flatten(), mu_pm[:, i], '-', color='green', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu_pm[:, i] - 2*std_pm[:, i], mu_morcgp[:, i] + 2*std_pm[:, i], color='green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-9, 7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 7))\n",
    "\n",
    "# Plot 1\n",
    "constant_mean = ConstantMean(constant=0)\n",
    "rcgp1 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=0.04, epsilon=epsilon)\n",
    "rcgp1.fit(x_train, y_train[:, 0].reshape(-1,1))\n",
    "rcgp1.optimize_loo_cv(weighted=False, print_opt_param=False)\n",
    "\n",
    "mu1, var1 = rcgp1.predict(x_test)\n",
    "std1 = np.sqrt(var1 + rcgp1.noise)\n",
    "\n",
    "axs[0, 0].plot(x_train[mask], y_train[mask, 0], 'o', color='black', alpha=0.5)\n",
    "axs[0, 0].plot(x_train[~mask], y_train[~mask, 0], 'o', color='red')\n",
    "axs[0, 0].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[0, 0].plot(x_test, mu1.ravel(), color=\"green\")\n",
    "axs[0, 0].fill_between(x_test.ravel(), mu1.ravel() - 1.96 * std1, mu1.ravel() + 1.96 * std1, alpha=0.3, color='green')\n",
    "axs[0, 0].set_title('$y_1$', fontsize=24, pad=10)\n",
    "\n",
    "# Plot 2\n",
    "rcgp2 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=0.04, epsilon=epsilon)\n",
    "rcgp2.fit(x_train, y_train[:, 1].reshape(-1,1))\n",
    "rcgp2.optimize_loo_cv(weighted=False, print_opt_param=False)\n",
    "\n",
    "mu2, var2 = rcgp2.predict(x_test)\n",
    "std2 = np.sqrt(var2 + rcgp2.noise)\n",
    "\n",
    "axs[0, 1].plot(x_train[mask], y_train[mask, 1], 'o', color='black', alpha=0.5)\n",
    "# axs[0, 1].plot(x_train[~mask], y_train[~mask, 1], 'o', color='red')\n",
    "axs[0, 1].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[0, 1].plot(x_test, mu2.ravel(), color=\"green\", label='RCGP')\n",
    "axs[0, 1].fill_between(x_test.ravel(), mu2.ravel() - 1.96 * std2, mu2.ravel() + 1.96 * std2, alpha=0.3, color='green')\n",
    "axs[0, 1].set_title('$y_2$', fontsize=24, pad=10)\n",
    "# axs[0, 1].legend()\n",
    "\n",
    "# Plot 3\n",
    "axs[1, 0].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[1, 0].plot(x_train.flatten(), y_train[:, 0], 'o', color='black', alpha=0.6)\n",
    "axs[1, 0].plot(x_train.flatten()[~mask], y_train[:, 0][~mask], 'o', color='red')\n",
    "axs[1, 0].plot(x_test.flatten(), mu_morcgp[:, 0], '-', color='royalblue', label='MORCGP')\n",
    "axs[1, 0].fill_between(x_test.flatten(), mu_morcgp[:, 0] - 2*std_morcgp[:, 0], mu_morcgp[:, 0] + 2*std_morcgp[:, 0], color='royalblue', alpha=0.2)\n",
    "\n",
    "# Plot 4\n",
    "axs[1, 1].plot(x_test, n_points * np.zeros((len(x_test), 1)), '--', color='grey')\n",
    "axs[1, 1].plot(x_train.flatten(), y_train[:, 1], 'o', color='black', alpha=0.6)\n",
    "axs[1, 1].plot(x_test.flatten(), mu_morcgp[:, 1], '-', color='royalblue', label='MORCGP')\n",
    "axs[1, 1].fill_between(x_test.flatten(), mu_morcgp[:, 1] - 2*std_morcgp[:, 1], mu_morcgp[:, 1] + 2*std_morcgp[:, 1], color='royalblue', alpha=0.2)\n",
    "# axs[1, 1].legend()\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_ylim([-5, 5])\n",
    "    ax.set_xticks([0, 0.5, 1])\n",
    "    ax.set_xlim([0, 1])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2) \n",
    "\n",
    "for i in range(2):\n",
    "    axs[i, 0].set_yticks([-4, 0, 4])          \n",
    "    axs[i, 1].set_yticks([-4, 0, 4])          \n",
    "    axs[i, 1].set_yticklabels([])            \n",
    "\n",
    "# for ax in axs[:, 0]:\n",
    "#     ax.set_ylabel('$y_1$', fontsize=24, rotation=0, labelpad=10, va='center', ha='right')\n",
    "\n",
    "# for ax in axs[:, 1]:\n",
    "#     ax.set_ylabel('$y_2$', fontsize=24, rotation=0, labelpad=25, va='center', ha='left')\n",
    "\n",
    "for ax in axs[0, :]:\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "prior_mean_line = mlines.Line2D([], [], color='grey', linestyle='--', label='Prior mean')\n",
    "rcgp_line = mlines.Line2D([], [], color='green', linestyle='-', label='RCGP')\n",
    "morcgp_line = mlines.Line2D([], [], color='royalblue', linestyle='-', label='MORCGP')\n",
    "\n",
    "fig.legend(handles=[prior_mean_line, rcgp_line, morcgp_line],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, -0.02),\n",
    "           ncol=3, frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 1]) \n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\"./results/synthetic_MOGP_MORCGP.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(18, 6))\n",
    "\n",
    "# Plot 1\n",
    "\n",
    "for i, ax in enumerate(axes[:2, 0]):\n",
    "    ax.plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, markersize=4, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        ax.plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', markersize=4, label='Outlier points')\n",
    "\n",
    "    ax.plot(x_test.flatten(), mu_morcgp[:, i], '-', color='royalblue', label='MORCGP')\n",
    "    ax.fill_between(x_test.flatten(), mu_morcgp[:, i] - 2*std_morcgp[:, i], mu_morcgp[:, i] + 2*std_morcgp[:, i], color='royalblue', alpha=0.2)\n",
    "\n",
    "    ax.set_ylim([-9, 5])\n",
    "    ax.set_xlim([0, 1])\n",
    "\n",
    "# Plot 2\n",
    "for i, ax in enumerate(axes[:2, 1]):\n",
    "    ax.plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, markersize=4, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        ax.plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', markersize=4, label='Outlier points')\n",
    "\n",
    "    ax.plot(x_test.flatten(), mu_pm[:, i], '-', color='green', label='RCGP')\n",
    "    ax.fill_between(x_test.flatten(), mu_pm[:, i] - 2*std_pm[:, i], mu_pm[:, i] + 2*std_pm[:, i], color='green', alpha=0.2)\n",
    "\n",
    "    ax.set_ylim([-9, 5])\n",
    "    ax.set_xlim([0, 1])\n",
    "\n",
    "# Plot 3\n",
    "for i, ax in enumerate(axes[:2, 2]):\n",
    "    ax.plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, markersize=4, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        ax.plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', markersize=4, label='Outlier points')\n",
    "\n",
    "    ax.plot(x_test.flatten(), mu_mogp[:, i], '-', color='orange', label='MOGP')\n",
    "    ax.fill_between(x_test.flatten(), mu_mogp[:, i] - 2*std_mogp[:, i], mu_mogp[:, i] + 2*std_mogp[:, i], color='orange', alpha=0.2)\n",
    "\n",
    "    ax.set_ylim([-9, 5])\n",
    "    ax.set_xlim([0, 1])\n",
    "\n",
    "# Plot 4\n",
    "for i, ax in enumerate(axes[:2, 3]):\n",
    "    ax.plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, markersize=4, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        ax.plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', markersize=4, label='Outlier points')\n",
    "\n",
    "    ax.plot(x_test.flatten(), mu_rcgp[:, i], '-', color='teal', label='RCGP')\n",
    "    ax.fill_between(x_test.flatten(), mu_rcgp[:, i] - 2*std_rcgp[:, i], mu_rcgp[:, i] + 2*std_rcgp[:, i], color='teal', alpha=0.2)\n",
    "\n",
    "    ax.set_ylim([-9, 5])\n",
    "    ax.set_xlim([0, 1])\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(1, 4):\n",
    "        axes[row, col].set_yticklabels([])\n",
    "\n",
    "for row in range(2):\n",
    "    axes[row, 0].yaxis.set_tick_params(labelleft=True)\n",
    "    for ax in axes[0, :]:\n",
    "        ax.set_xticklabels([])\n",
    "    for ax in axes[1, :]:\n",
    "        ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(4):\n",
    "        axes[row, col].set_xticks([0, 0.5])\n",
    "\n",
    "        for row in range(2):\n",
    "            for col in range(4):\n",
    "                for spine in axes[row, col].spines.values():\n",
    "                    spine.set_linewidth(2)\n",
    "\n",
    "                    axes[0, 0].set_ylabel('$y_1$', fontsize=18, labelpad=10, rotation=0)\n",
    "                    axes[1, 0].set_ylabel('$y_2$', fontsize=18, labelpad=10, rotation=0)\n",
    "        \n",
    "        titles = [r\"MORCGP ($w_{\\scriptscriptstyle\\textrm{MORCGP}}$)\", r\"MORCGP ($w_{\\scriptscriptstyle\\textrm{RCGP}}$)\", \"MOGP\", \"RCGP\"]\n",
    "        for col, title in enumerate(titles):\n",
    "            axes[0, col].set_title(title, fontsize=18, pad=12)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b40525",
   "metadata": {},
   "source": [
    "## Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bc211",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "# print(i)\n",
    "# Initialisation\n",
    "constant_mean = 0\n",
    "length_scale = 0.1\n",
    "variance = 1\n",
    "n_outputs = 2\n",
    "n_points = 120\n",
    "overlap_ratio = 1\n",
    "epsilon = 0.05\n",
    "\n",
    "A = np.array([[1.414, 0], \n",
    "    [0.884, 0.468]])\n",
    "B = A @ A.T\n",
    "print(B)\n",
    "\n",
    "D = B.shape[0]\n",
    "\n",
    "noise1 = 0.05\n",
    "noise2 = 0.05\n",
    "noise = np.array([noise1, noise2])\n",
    "if noise.shape[0] == 1:\n",
    "    noise_matrix = noise * np.eye(D)\n",
    "else:\n",
    "    noise_matrix = np.diag(noise)\n",
    "\n",
    "# Simulation\n",
    "mean_func = ConstantMean(constant=constant_mean)\n",
    "rbf_kernel = RBFKernel(lengthscale=length_scale, variance=1)\n",
    "\n",
    "x_train = np.sort(np.random.uniform(0, 1, n_points)).reshape(-1, 1)\n",
    "N = len(x_train)\n",
    "kernel_train = rbf_kernel(x_train, x_train)\n",
    "K_train = np.kron(B, kernel_train)\n",
    "K_train_noise = K_train + np.kron(noise_matrix, np.eye(len(x_train))) + 1e-6 * np.eye(len(x_train) * D)\n",
    "y_train = np.random.multivariate_normal(np.tile(mean_func(x_train).flatten(), D), K_train_noise).reshape(D, -1).T\n",
    "\n",
    "y_train = apply_overlap(y_train, overlap_ratio)\n",
    "\n",
    "outlier_range = np.where((x_train >= 0.42) & (x_train <= 0.58))[0]\n",
    "outlier_indices = np.random.choice(outlier_range, int(epsilon*n_points), replace=False)\n",
    "y_train[outlier_indices, 0] = np.random.normal(loc=2.5, scale=0.5, size=outlier_indices.shape[0])\n",
    "\n",
    "mask = np.ones(len(x_train), dtype=bool)\n",
    "mask[outlier_indices] = False\n",
    "\n",
    "y_train -= np.mean(y_train, axis=0)\n",
    "\n",
    "x_test = np.linspace(0, 1, 1000).reshape(-1, 1)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1}')\n",
    "    if i == 0:\n",
    "        axs[i].plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', label='Outlier points')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-5, 5])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54394a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOGP\n",
    "mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "# mogp = MOGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=A)\n",
    "mogp.fit(x_train, y_train)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "optim_length_scale = mogp.length_scale\n",
    "optim_B = mogp.B\n",
    "optim_A = mogp.A\n",
    "optim_noise = mogp.noise\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "# MORCGP\n",
    "morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=optim_A)\n",
    "# morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_length_scale, noise = optim_noise, A=optim_A)\n",
    "predictive_mean, predictive_variances = morcgp.fit(x_train, y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=length_scale, noise=np.array([0.05, 0.05]), A=A, weighted=True))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, \n",
    "                    #    B_weighted=optim_B, noise_weighted=optim_noise\n",
    "                       )\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "# RCGP\n",
    "y_train1, y_train2 = y_train[:, 0].reshape(-1,1), y_train[:, 1].reshape(-1,1)\n",
    "\n",
    "mu_rcgp = np.full((len(x_test), 2), np.nan)\n",
    "std_rcgp = np.full((len(x_test), 2), np.nan)\n",
    "\n",
    "constant_mean = ConstantMean(constant=0)\n",
    "rcgp1 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=noise1, epsilon=epsilon)\n",
    "rcgp1.fit(x_train, y_train1)\n",
    "rcgp1.optimize_loo_cv(weighted=False, print_opt_param=False)\n",
    "\n",
    "mu_rcgp[:, 0], var_rcgp = rcgp1.predict(x_test)\n",
    "std_rcgp[:, 0] = np.sqrt(var_rcgp + rcgp1.noise)\n",
    "\n",
    "rcgp2 = RCGPRegressor(mean=constant_mean, length_scale=0.2, rbf_variance=2, noise=noise2, epsilon=epsilon)\n",
    "rcgp2.fit(x_train, y_train2)\n",
    "rcgp2.optimize_loo_cv(weighted=False, print_opt_param=False)\n",
    "\n",
    "mu_rcgp[:, 1], var2 = rcgp2.predict(x_test)\n",
    "std_rcgp[:, 1] = np.sqrt(var2 + rcgp2.noise)\n",
    "\n",
    "# MORCGP\n",
    "morcgp = MORCGPRegressor_PM(mean = 0, length_scale=optim_length_scale, noise = noise, A=optim_A, epsilons=np.array([epsilon, 0]))\n",
    "morcgp.fit(x_train, y_train)\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=0.1, noise=0.04, A=A, weighted=True, B_weighted=B))\n",
    "\n",
    "# Optimize hyperparameters\n",
    "morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, \n",
    "                    #    B_weighted=optim_B, noise_weighted=optim_noise\n",
    "                       )\n",
    "\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "mu_pm, var_pm = morcgp.predict(x_test)\n",
    "std_pm = np.sqrt(var_pm + morcgp.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [\n",
    "    {\"mu\": mu_morcgp, \"std\": std_morcgp, \"label\": r\"MORCGP ($w_{\\scriptscriptstyle\\textrm{MORCGP}}$)\", \"color\": \"royalblue\"},\n",
    "    {\"mu\": mu_pm, \"std\": std_pm, \"label\": r\"MORCGP ($w_{\\scriptscriptstyle\\textrm{RCGP}}$)\", \"color\": \"orange\"},\n",
    "    {\"mu\": mu_mogp, \"std\": std_mogp, \"label\": \"MOGP\", \"color\": \"green\"},\n",
    "    {\"mu\": mu_rcgp, \"std\": std_rcgp, \"label\": \"RCGP\", \"color\": \"teal\"},\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(18, 5.5), gridspec_kw={'height_ratios': [1, 0.6]})\n",
    "\n",
    "def plot_model(ax, i, mu, std, color, label):\n",
    "    ax.axhline(0, color='grey', linestyle='--', linewidth=3)  # Add y=0 line\n",
    "    ax.plot(x_train.flatten(), y_train[:, i], 'o', color='black', alpha=0.6, markersize=4)\n",
    "    if i == 0:\n",
    "        ax.plot(x_train.flatten()[~mask], y_train[:, i][~mask], 'o', color='red', markersize=4, label='Outliers')\n",
    "    ax.plot(x_test.flatten(), mu[:, i], '-', color=color, label=label)\n",
    "    ax.fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color=color, alpha=0.2)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_xticks([0, 0.5])\n",
    "    if i == 0:\n",
    "        ax.set_ylim([-6, 6])\n",
    "    else:\n",
    "        ax.set_ylim([-3, 3])\n",
    "\n",
    "for col, model in enumerate(models):\n",
    "    for row in range(2):\n",
    "        ax = axes[row, col]\n",
    "        plot_model(ax, row, model[\"mu\"], model[\"std\"], model[\"color\"], model[\"label\"])\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(4):\n",
    "        ax = axes[row, col]\n",
    "        if col > 0:\n",
    "            ax.set_yticklabels([])\n",
    "        if row == 0:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.xaxis.set_tick_params(labelbottom=True)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "\n",
    "axes[0, 0].set_ylabel('$y_1$', fontsize=18, labelpad=10, rotation=0)\n",
    "axes[1, 0].set_ylabel('$y_2$', fontsize=18, labelpad=10, rotation=0)\n",
    "\n",
    "axes[0, 0].set_yticks([-4, 0, 4])\n",
    "axes[1, 0].set_yticks([-2, 0, 2])\n",
    "\n",
    "for col in range(4):\n",
    "    axes[1, col].set_xlabel(r'$x$', fontsize=16)\n",
    "\n",
    "for col, model in enumerate(models):\n",
    "    axes[0, col].set_title(model[\"label\"], fontsize=24, pad=12)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\"./results/synthetic_MOGP_MORCGP.pdf\", format='pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
