{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf6aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor, MORCGPRegressor, MOGPRegressor_NC, MORCGPRegressor_NC, MORCGPRegressor_NC_fixed_weights, MORCGPRegressor_fixed_weights, MORCGPRegressor_PM, MORCGP\n",
    "from rcgp.rcgp import RCGPRegressor\n",
    "from rcgp.kernels import ConstantMean, RBFKernel, SineMean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import cholesky\n",
    "from sklearn.covariance import MinCovDet\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 24,         \n",
    "    'axes.labelsize': 24,    \n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 20,\n",
    "    'lines.linewidth': 4,    \n",
    "    'lines.markersize': 5   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165c76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_random(x, Y, N_train):\n",
    "    total_samples = x.shape[0]\n",
    "    all_indices = np.arange(total_samples)\n",
    "    \n",
    "    train_indices = np.random.choice(all_indices, size=N_train, replace=False)\n",
    "    test_indices = np.setdiff1d(all_indices, train_indices)\n",
    "    \n",
    "    train_indices = np.sort(train_indices)\n",
    "    test_indices = np.sort(test_indices)\n",
    "    \n",
    "    x_train = x[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    x_test = x[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    \n",
    "    return x_train, Y_train, x_test, Y_test\n",
    "\n",
    "def generate_A(d, r=1, base_strength=1.0, noise_level=0.1, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    # Shared signal: induces positive correlations\n",
    "    shared_component = base_strength * np.ones((d, r))\n",
    "    # Small random noise to avoid exact collinearity\n",
    "    noise = noise_level * np.random.randn(d, r)\n",
    "    A = shared_component + noise\n",
    "    return A\n",
    "\n",
    "def rbf_kernel(x1, x2, lengthscale=1.0, variance=1.0):\n",
    "    sqdist = np.sum(x1**2, 1).reshape(-1,1) + np.sum(x2**2,1) - 2*np.dot(x1, x2.T)\n",
    "    return variance * np.exp(-0.5 / lengthscale**2 * sqdist)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def nlpd(Y_true, mu_pred, var_pred):\n",
    "    epsilon = 1e-10\n",
    "    var_pred = np.maximum(var_pred, epsilon)\n",
    "    \n",
    "    nlpd_values = 0.5 * np.log(2 * np.pi * var_pred) + ((Y_true - mu_pred) ** 2) / (2 * var_pred)\n",
    "    \n",
    "    return np.mean(nlpd_values)\n",
    "\n",
    "def cov_to_corr(cov):\n",
    "    stddev = np.sqrt(np.diag(cov))        # standard deviations\n",
    "    corr = cov / np.outer(stddev, stddev) # normalize\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2e43f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers per column: [ 8  8 10 10]\n",
      "[[1.         0.89388693 0.93824366 0.94688773]\n",
      " [0.89388693 1.         0.79230207 0.85075139]\n",
      " [0.93824366 0.79230207 1.         0.95960702]\n",
      " [0.94688773 0.85075139 0.95960702 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:15<00:00, 75.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MOGP: 0.3347 ± 0.0000\n",
      "RMSE MORCGP (PM): 0.3415 ± 0.0000\n",
      "RMSE MORCGP: 0.2020 ± 0.0000\n",
      "NLPD MOGP: 1.0472 ± 0.0000\n",
      "NLPD MORCGP (PM): 0.6575 ± 0.0000\n",
      "NLPD MORCGP: 0.8485 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "introduce_outliers = True\n",
    "introduce_missing_values = True\n",
    "\n",
    "rmses_mogp_outliers, rmses_morcgp_outliers, rmses_pm_outliers = [], [], []\n",
    "nlpds_mogp_outliers, nlpds_morcgp_outliers, nlpds_pm_outliers = [], [], []\n",
    "\n",
    "N, D = 100, 4\n",
    "noise_var = 0.1\n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  0.7,  0.5],\n",
    "    [0.9,  1.0,  0.8,  0.6],\n",
    "    [0.7, 0.8,  1.0, 0.9],\n",
    "    [0.5,  0.6,  0.9,  1.0],\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "epsilons = np.array([epsilon] * D)\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    # Add a small jitter for numerical stability\n",
    "    L = cholesky(K + 1e-6*np.eye(D*N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*N)\n",
    "    F = f_samples.reshape(D, N).T\n",
    "    Y_test = F + np.random.normal(0, noise_var, F.shape)\n",
    "    Y_train = Y_test.copy()\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Example flags\n",
    "    introduce_missing_values = True\n",
    "    introduce_outliers = True\n",
    "    epsilon = 0.1  # fraction of non-NaN values to become outliers\n",
    "\n",
    "    # Assume Y_train is 2D: shape (n_rows, n_cols)\n",
    "    n_rows, n_cols = Y_train.shape\n",
    "    outliers_mask = np.zeros_like(Y_train, dtype=bool)\n",
    "\n",
    "    # --- Step 1: Introduce missing values ---\n",
    "    if introduce_missing_values:\n",
    "        # First output: replace first 20% with NaN\n",
    "        first_20pct = int(0.2 * n_rows)\n",
    "        Y_train[:first_20pct, 0] = np.nan\n",
    "\n",
    "        # Second output: replace last 20% with NaN\n",
    "        last_20pct = int(0.2 * n_rows)\n",
    "        Y_train[-last_20pct:, 1] = np.nan\n",
    "\n",
    "    # --- Step 2: Introduce outliers ---\n",
    "    if introduce_outliers:\n",
    "        for col in range(n_cols):\n",
    "            # Indices of non-NaN values in this column\n",
    "            non_nan_rows = np.where(~np.isnan(Y_train[:, col]))[0]\n",
    "            n_non_nan = len(non_nan_rows)\n",
    "\n",
    "            # Number of outliers based on non-NaN values\n",
    "            num_outliers = int(epsilon * n_non_nan)\n",
    "\n",
    "            # Randomly select outlier indices from non-NaN rows\n",
    "            if num_outliers > 0:\n",
    "                outlier_rows = np.random.choice(non_nan_rows, num_outliers, replace=False)\n",
    "\n",
    "                for row in outlier_rows:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        Y_train[row, col] = np.random.uniform(-4, -2)  # negative outlier\n",
    "                    else:\n",
    "                        Y_train[row, col] = np.random.uniform(2, 4)    # positive outlier\n",
    "\n",
    "                # Update outlier mask\n",
    "                outliers_mask[outlier_rows, col] = True\n",
    "\n",
    "        # Count outliers per column\n",
    "        outliers_per_column = np.sum(outliers_mask, axis=0)\n",
    "        print(\"Outliers per column:\", outliers_per_column)\n",
    "        \n",
    "    \n",
    "\n",
    "    # MOGP\n",
    "    mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([0.1] * D), A = A)\n",
    "    mogp.fit(x, Y_train)\n",
    "    mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "    mu_mogp, var_mogp = mogp.predict(x)\n",
    "    std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "    # MORCGP\n",
    "    Y_train_clean = Y_train[~np.isnan(Y_train).any(axis=1)]\n",
    "    mcd = MinCovDet(support_fraction=0.6).fit(Y_train_clean)\n",
    "    robust_covariance = mcd.covariance_\n",
    "    print(cov_to_corr(robust_covariance))\n",
    "    \n",
    "    morcgp = MORCGP(mean=0, length_scale=1, noise_var=np.array([0.1]*D), A=A)\n",
    "    morcgp.fit(x, Y_train, epsilons=epsilons)\n",
    "    morcgp.optimize_loo_cv(print_opt_param=False, print_iter_objective=False, k=1, init_cov=robust_covariance, fix_weights=True)\n",
    "\n",
    "    mu_morcgp, var_morcgp = morcgp.predict(x)\n",
    "    std_morcgp = np.sqrt(var_morcgp + morcgp.noise_var)\n",
    "\n",
    "    # MORCGP (RCGP weights)\n",
    "    morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=1.0, noise=np.array([0.1]*D), A=A, epsilons=epsilons)\n",
    "    morcgp_pm.fit(x, Y_train)\n",
    "    morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    mu_pm, var_pm = morcgp_pm.predict(x)\n",
    "    std_pm = np.sqrt(var_pm + morcgp_pm.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_mogp = calculate_rmse(Y_test, mu_mogp)\n",
    "    rmse_pm = calculate_rmse(Y_test, mu_pm)\n",
    "    rmse_morcgp = calculate_rmse(Y_test, mu_morcgp)\n",
    "\n",
    "    rmses_mogp_outliers.append(rmse_mogp)\n",
    "    rmses_pm_outliers.append(rmse_pm)\n",
    "    rmses_morcgp_outliers.append(rmse_morcgp)\n",
    "\n",
    "    nlpd_mogp = nlpd(Y_test, mu_mogp, std_mogp**2)\n",
    "    nlpd_pm = nlpd(Y_test, mu_pm, std_pm**2)\n",
    "    nlpd_morcgp = nlpd(Y_test, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "    nlpds_mogp_outliers.append(nlpd_mogp)\n",
    "    nlpds_pm_outliers.append(nlpd_pm)\n",
    "    nlpds_morcgp_outliers.append(nlpd_morcgp)\n",
    "\n",
    "print(f'RMSE MOGP: {np.mean(rmses_mogp_outliers):.4f} ± {np.std(rmses_mogp_outliers):.4f}')\n",
    "print(f'RMSE MORCGP (PM): {np.mean(rmses_pm_outliers):.4f} ± {np.std(rmses_pm_outliers):.4f}')\n",
    "print(f'RMSE MORCGP: {np.mean(rmses_morcgp_outliers):.4f} ± {np.std(rmses_morcgp_outliers):.4f}')\n",
    "\n",
    "print(f'NLPD MOGP: {np.mean(nlpds_mogp_outliers):.4f} ± {np.std(nlpds_mogp_outliers):.4f}')\n",
    "print(f'NLPD MORCGP (PM): {np.mean(nlpds_pm_outliers):.4f} ± {np.std(nlpds_pm_outliers):.4f}')\n",
    "print(f'NLPD MORCGP: {np.mean(nlpds_morcgp_outliers):.4f} ± {np.std(nlpds_morcgp_outliers):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
