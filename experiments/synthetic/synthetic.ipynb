{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c882551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor, MORCGPRegressor, MOGPRegressor_NC, MORCGPRegressor_NC, MORCGPRegressor_NC_fixed_weights, MORCGPRegressor_fixed_weights, MORCGPRegressor_PM\n",
    "from rcgp.rcgp import RCGPRegressor\n",
    "from rcgp.kernels import ConstantMean, RBFKernel, SineMean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 24,         \n",
    "    'axes.labelsize': 24,    \n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 20,\n",
    "    'lines.linewidth': 4,    \n",
    "    'lines.markersize': 5   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_random(x, Y, N_train):\n",
    "    total_samples = x.shape[0]\n",
    "    all_indices = np.arange(total_samples)\n",
    "    \n",
    "    train_indices = np.random.choice(all_indices, size=N_train, replace=False)\n",
    "    test_indices = np.setdiff1d(all_indices, train_indices)\n",
    "    \n",
    "    train_indices = np.sort(train_indices)\n",
    "    test_indices = np.sort(test_indices)\n",
    "    \n",
    "    x_train = x[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    x_test = x[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    \n",
    "    return x_train, Y_train, x_test, Y_test\n",
    "\n",
    "def introduce_missing_values(Y, missing_percentage):\n",
    "    num_elements = Y.size\n",
    "    num_nan = int(missing_percentage * num_elements)\n",
    "\n",
    "    nan_indices = np.random.choice(num_elements, num_nan, replace=False)\n",
    "\n",
    "    Y_flat = Y.flatten().copy()\n",
    "\n",
    "    Y_flat[nan_indices] = np.nan\n",
    "\n",
    "    return Y_flat.reshape(Y.shape)\n",
    "\n",
    "def rbf_kernel(x1, x2, lengthscale=1.0, variance=1.0):\n",
    "    sqdist = np.sum(x1**2, 1).reshape(-1,1) + np.sum(x2**2,1) - 2*np.dot(x1, x2.T)\n",
    "    return variance * np.exp(-0.5 / lengthscale**2 * sqdist)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def nlpd(Y_true, mu_pred, var_pred):\n",
    "    epsilon = 1e-10\n",
    "    var_pred = np.maximum(var_pred, epsilon)\n",
    "    \n",
    "    nlpd_values = 0.5 * np.log(2 * np.pi * var_pred) + ((Y_true - mu_pred) ** 2) / (2 * var_pred)\n",
    "    \n",
    "    return np.mean(nlpd_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de25644b",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2eb9a",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481c383",
   "metadata": {},
   "source": [
    "Simulation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N = 100\n",
    "D = 5 \n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "\n",
    "x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "K = np.kron(B, Kx)\n",
    "\n",
    "L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "f_samples = L @ np.random.randn(D*train_test_N)\n",
    "F = f_samples.reshape(D, train_test_N).T\n",
    "Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "num_outliers = int(epsilon * N * D * (1 - missing_percentage))\n",
    "indices = np.unravel_index(np.random.choice(N * D, num_outliers, replace=False), (N, D))\n",
    "uniform_outliers = np.random.uniform(0, 1, num_outliers)\n",
    "outlier_values = np.where(\n",
    "    uniform_outliers < 0.5,\n",
    "    np.random.uniform(3, 5, num_outliers),\n",
    "    np.random.uniform(-5, -3, num_outliers)\n",
    ")\n",
    "Y_train[indices] = outlier_values\n",
    "\n",
    "outliers_per_channel = np.bincount(indices[1])\n",
    "non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "\n",
    "epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "print(outliers_per_channel)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "outlier_mask = np.zeros((N, D), dtype=bool)\n",
    "outlier_mask[indices] = True\n",
    "\n",
    "for i in range(D):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    \n",
    "    x_all = x_train.flatten()\n",
    "    y_all = Y_train[:, i]\n",
    "    is_outlier = outlier_mask[:, i]\n",
    "\n",
    "    ax.plot(x_all[~is_outlier], y_all[~is_outlier], 'o', color='black', alpha=0.6, label=f'Output {i+1} - inliers')\n",
    "    ax.plot(x_all[is_outlier], y_all[is_outlier], 'o', color='red', alpha=0.8, label='Outliers')\n",
    "\n",
    "    ax.set_ylim([-6, 6])\n",
    "    if i % 3 != 0:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b734ce",
   "metadata": {},
   "source": [
    "## MOGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([0.2] * D), A = 2*A)\n",
    "mogp.fit(x_train, Y_train)\n",
    "\n",
    "mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "\n",
    "optim_noise = mogp.noise\n",
    "optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "# Predict on test points\n",
    "mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b4faa",
   "metadata": {},
   "source": [
    "## MORCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "initial_predictive_mean, initial_predictive_variances = morcgp.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf7339",
   "metadata": {},
   "source": [
    "## MORCGP (RCGP weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=epsilons)\n",
    "morcgp_pm.fit(x_train, Y_train)\n",
    "\n",
    "morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "std_pm = np.sqrt(var_pm + morcgp_pm.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7051ce",
   "metadata": {},
   "source": [
    "## RCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2560c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = ConstantMean(constant=0.0)\n",
    "mu_rcgp, std_rcgp = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "\n",
    "for d in range(D):\n",
    "    rcgp = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "    rcgp.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "    rcgp.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "    mu_rcgp[:, d], var_rcgp = rcgp.predict(x_test)\n",
    "    std_rcgp[:, d] = np.sqrt(var_rcgp + rcgp.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cdb78",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 5))\n",
    "\n",
    "for i in range(D):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    x_all = x_train.flatten()\n",
    "    y_all = Y_train[:, i]\n",
    "    is_outlier = outlier_mask[:, i]\n",
    "\n",
    "    ax.plot(x_all[~is_outlier], y_all[~is_outlier], 'o', color='black', alpha=0.6, label=f'Output {i+1} - inliers')\n",
    "    ax.plot(x_all[is_outlier], y_all[is_outlier], 'o', color='red', alpha=0.8, label='Outliers')\n",
    "\n",
    "    # MOGP\n",
    "    ax.plot(x_test.flatten(), mu_mogp[:, i], '-', color='Green', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_mogp[:, i] - 2*std_mogp[:, i], mu_mogp[:, i] + 2*std_mogp[:, i], color='Blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # MORCGP\n",
    "    ax.plot(x_test.flatten(), mu_morcgp[:, i], '-', color='RoyalBlue', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_morcgp[:, i] - 2*std_morcgp[:, i], mu_morcgp[:, i] + 2*std_morcgp[:, i], color='Green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # Predictive mean and variance\n",
    "    # ax.plot(x_train.flatten(), predictive_mean[:, i], '-', color='red', label=f'Predictive Mean')\n",
    "    # ax.fill_between(x_train.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances)[:, i], predictive_mean[:, i] + np.sqrt(predictive_variances)[:, i], color='red', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # ax.plot(x_train.flatten(), initial_predictive_mean[:, i], '-', color='green', label=f'Predictive Mean')\n",
    "    # ax.fill_between(x_train.flatten(), initial_predictive_mean[:, i] - np.sqrt(initial_predictive_variances)[:, i], initial_predictive_mean[:, i] + np.sqrt(initial_predictive_variances)[:, i], color='green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # RCGP\n",
    "    ax.plot(x_test.flatten(), mu_rcgp[:, i], '-', color='Orange', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_rcgp[:, i] - 2*std_rcgp[:, i], mu_rcgp[:, i] + 2*std_rcgp[:, i], color='Red', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # MORCGP (RCGP weights)\n",
    "    ax.plot(x_test.flatten(), mu_pm[:, i], '-', color='Teal', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_pm[:, i] - 2*std_pm[:, i], mu_pm[:, i] + 2*std_pm[:, i], color='Teal', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    ax.set_ylim([-6, 6])\n",
    "    if i % 3 != 0:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "# Hide the unused 6th subplot\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test, mu_morcgp)\n",
    "rmse_rcgp = calculate_rmse(Y_test, mu_rcgp)\n",
    "rmse_pm = calculate_rmse(Y_test, mu_pm)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "print(\"RMSE RCGP:\", rmse_rcgp)\n",
    "print(\"RMSE MORCGP (PM):\", rmse_pm)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test, mu_morcgp, std_morcgp**2)\n",
    "nlpd_rcgp = nlpd(Y_test, mu_rcgp, std_rcgp**2)\n",
    "nlpd_pm = nlpd(Y_test, mu_pm, std_pm**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)\n",
    "print(\"NLPD RCGP:\", nlpd_rcgp)\n",
    "print(\"NLPD MORCGP (PM):\", nlpd_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75611b",
   "metadata": {},
   "source": [
    "# No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N = 100\n",
    "D = 5 \n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1\n",
    "\n",
    "x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "K = np.kron(B, Kx)\n",
    "\n",
    "L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "f_samples = L @ np.random.randn(D*train_test_N)\n",
    "F = f_samples.reshape(D, train_test_N).T\n",
    "Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "outliers_per_channel = np.bincount(indices[1])\n",
    "non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "\n",
    "epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "print(outliers_per_channel)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i in range(D):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    \n",
    "    ax.plot(x_train, Y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1} - inliers')\n",
    "\n",
    "    ax.set_ylim([-6, 6])\n",
    "    if i % 3 != 0:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([noise_var] * D), A = 2*A)\n",
    "mogp.fit(x_train, Y_train)\n",
    "mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "\n",
    "optim_noise = mogp.noise\n",
    "optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([noise_var]*D), A=A)\n",
    "initial_predictive_mean, initial_predictive_variances = morcgp.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=[0]*D)\n",
    "morcgp_pm.fit(x_train, Y_train)\n",
    "morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "std_pm = np.sqrt(var_pm + morcgp_pm.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "mu_rcgp, std_rcgp = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "\n",
    "for d in range(D):\n",
    "    rcgp = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=0)\n",
    "    rcgp.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "\n",
    "    rcgp.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "\n",
    "    mu_rcgp[:, d], var_rcgp = rcgp.predict(x_test)\n",
    "    std_rcgp[:, d] = np.sqrt(var_rcgp + rcgp.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc84d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 5))\n",
    "\n",
    "for i in range(D):\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    ax.plot(x_train, Y_train[:, i], 'o', color='black', alpha=0.6, label=f'Output {i+1} - inliers')\n",
    "\n",
    "    # MOGP\n",
    "    ax.plot(x_test.flatten(), mu_mogp[:, i], '-', color='Green', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_mogp[:, i] - 2*std_mogp[:, i], mu_mogp[:, i] + 2*std_mogp[:, i], color='Blue', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # MORCGP\n",
    "    ax.plot(x_test.flatten(), mu_morcgp[:, i], '-', color='RoyalBlue', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_morcgp[:, i] - 2*std_morcgp[:, i], mu_morcgp[:, i] + 2*std_morcgp[:, i], color='Green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # Predictive mean and variance\n",
    "    # ax.plot(x_train.flatten(), predictive_mean[:, i], '-', color='red', label=f'Predictive Mean')\n",
    "    # ax.fill_between(x_train.flatten(), predictive_mean[:, i] - np.sqrt(predictive_variances)[:, i], predictive_mean[:, i] + np.sqrt(predictive_variances)[:, i], color='red', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # ax.plot(x_train.flatten(), initial_predictive_mean[:, i], '-', color='green', label=f'Predictive Mean')\n",
    "    # ax.fill_between(x_train.flatten(), initial_predictive_mean[:, i] - np.sqrt(initial_predictive_variances)[:, i], initial_predictive_mean[:, i] + np.sqrt(initial_predictive_variances)[:, i], color='green', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # RCGP\n",
    "    ax.plot(x_test.flatten(), mu_rcgp[:, i], '-', color='Orange', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_rcgp[:, i] - 2*std_rcgp[:, i], mu_rcgp[:, i] + 2*std_rcgp[:, i], color='Red', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    # MORCGP (RCGP weights)\n",
    "    ax.plot(x_test.flatten(), mu_pm[:, i], '-', color='Teal', label=f'Predicted Mean')\n",
    "    # ax.fill_between(x_test.flatten(), mu_pm[:, i] - 2*std_pm[:, i], mu_pm[:, i] + 2*std_pm[:, i], color='Teal', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    ax.set_ylim([-6, 6])\n",
    "    if i % 3 != 0:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "# Hide the unused 6th subplot\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb07018",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test, mu_morcgp)\n",
    "rmse_rcgp = calculate_rmse(Y_test, mu_rcgp)\n",
    "rmse_pm = calculate_rmse(Y_test, mu_pm)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "print(\"RMSE RCGP:\", rmse_rcgp)\n",
    "print(\"RMSE MORCGP (PM):\", rmse_pm)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test, mu_morcgp, std_morcgp**2)\n",
    "nlpd_rcgp = nlpd(Y_test, mu_rcgp, std_rcgp**2)\n",
    "nlpd_pm = nlpd(Y_test, mu_pm, std_pm**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)\n",
    "print(\"NLPD RCGP:\", nlpd_rcgp)\n",
    "print(\"NLPD MORCGP (PM):\", nlpd_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a00d6",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_rcgp, rmses_pm = [], [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_rcgp, nlpds_pm = [], [], [], []\n",
    "\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1\n",
    "\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "    Y -= np.mean(Y, axis=0)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    # MOGP\n",
    "    mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([noise_var] * D), A = 2*A)\n",
    "    mogp.fit(x_train, Y_train)\n",
    "    mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "    optim_noise = mogp.noise\n",
    "    optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "    mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "    std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "    # MORCGP\n",
    "    morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([noise_var]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "    std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "    # MORCGP (RCGP weights)\n",
    "    morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=[0]*D)\n",
    "    morcgp_pm.fit(x_train, Y_train)\n",
    "    morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "    std_pm = np.sqrt(var_pm + morcgp_pm.noise)\n",
    "\n",
    "    # RCGP\n",
    "    mu_rcgp, std_rcgp = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "\n",
    "    for d in range(D):\n",
    "        rcgp = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=0)\n",
    "        rcgp.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "\n",
    "        rcgp.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "\n",
    "        mu_rcgp[:, d], var_rcgp = rcgp.predict(x_test)\n",
    "        std_rcgp[:, d] = np.sqrt(var_rcgp + rcgp.noise)\n",
    "\n",
    "    rmse_mogp = calculate_rmse(Y_test, mu_mogp)\n",
    "    rmse_morcgp = calculate_rmse(Y_test, mu_morcgp)\n",
    "    rmse_rcgp = calculate_rmse(Y_test, mu_rcgp)\n",
    "    rmse_pm = calculate_rmse(Y_test, mu_pm)\n",
    "\n",
    "    # print(\"RMSE MOGP:\", rmse_mogp)\n",
    "    # print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "    # print(\"RMSE RCGP:\", rmse_rcgp)\n",
    "    # print(\"RMSE MORCGP (PM):\", rmse_pm)\n",
    "\n",
    "    rmses_mogp.append(rmse_mogp)\n",
    "    rmses_morcgp.append(rmse_morcgp)\n",
    "    rmses_rcgp.append(rmse_rcgp)\n",
    "    rmses_pm.append(rmse_pm)\n",
    "\n",
    "    nlpd_mogp = nlpd(Y_test, mu_mogp, std_mogp**2)\n",
    "    nlpd_morcgp = nlpd(Y_test, mu_morcgp, std_morcgp**2)\n",
    "    nlpd_rcgp = nlpd(Y_test, mu_rcgp, std_rcgp**2)\n",
    "    nlpd_pm = nlpd(Y_test, mu_pm, std_pm**2)\n",
    "\n",
    "    # print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "    # print(\"NLPD MORCGP:\", nlpd_morcgp)\n",
    "    # print(\"NLPD RCGP:\", nlpd_rcgp)\n",
    "    # print(\"NLPD MORCGP (PM):\", nlpd_pm)\n",
    "\n",
    "    nlpds_mogp.append(nlpd_mogp)\n",
    "    nlpds_morcgp.append(nlpd_morcgp)\n",
    "    nlpds_rcgp.append(nlpd_rcgp)\n",
    "    nlpds_pm.append(nlpd_pm)\n",
    "\n",
    "print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "print(f'RMSE RCGP: {np.mean(rmses_rcgp):.4f} ± {np.std(rmses_rcgp):.4f}')\n",
    "print(f'RMSE MORCGP (PM): {np.mean(rmses_pm):.4f} ± {np.std(rmses_pm):.4f}')\n",
    "\n",
    "print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "print(f'NLPD RCGP: {np.mean(nlpds_rcgp):.4f} ± {np.std(nlpds_rcgp):.4f}')\n",
    "print(f'NLPD MORCGP (PM): {np.mean(nlpds_pm):.4f} ± {np.std(nlpds_pm):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmses_mogp)\n",
    "print(rmses_morcgp)\n",
    "print(rmses_rcgp)\n",
    "print(rmses_pm)\n",
    "\n",
    "print(nlpds_mogp)\n",
    "print(nlpds_morcgp)\n",
    "print(nlpds_rcgp)\n",
    "print(nlpds_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_mogp_list = [x.item() for x in rmses_mogp]\n",
    "rmses_morcgp_list = [x.item() for x in rmses_morcgp]\n",
    "rmses_rcgp_list = [x.item() for x in rmses_rcgp]\n",
    "rmses_pm_list = [x.item() for x in rmses_pm]\n",
    "\n",
    "nlpds_mogp_list = [x.item() for x in nlpds_mogp]\n",
    "nlpds_morcgp_list = [x.item() for x in nlpds_morcgp]\n",
    "nlpds_rcgp_list = [x.item() for x in nlpds_rcgp]\n",
    "nlpds_pm_list = [x.item() for x in nlpds_pm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE MOGP: {np.mean(rmses_mogp_list):.3f} ± {np.std(rmses_mogp_list):.3f}')\n",
    "print(f'RMSE MORCGP: {np.mean(rmses_morcgp_list):.3f} ± {np.std(rmses_morcgp_list):.3f}')\n",
    "print(f'RMSE RCGP: {np.mean(rmses_rcgp_list):.3f} ± {np.std(rmses_rcgp_list):.3f}')\n",
    "print(f'RMSE MORCGP (PM): {np.mean(rmses_pm_list):.3f} ± {np.std(rmses_pm_list):.3f}')\n",
    "\n",
    "print(f'NLPD MOGP: {np.mean(nlpds_mogp_list):.3f} ± {np.std(nlpds_mogp_list):.3f}')\n",
    "print(f'NLPD MORCGP: {np.mean(nlpds_morcgp_list):.3f} ± {np.std(nlpds_morcgp_list):.3f}')\n",
    "print(f'NLPD RCGP: {np.mean(nlpds_rcgp_list):.3f} ± {np.std(nlpds_rcgp_list):.3f}')\n",
    "print(f'NLPD MORCGP (PM): {np.mean(nlpds_pm_list):.3f} ± {np.std(nlpds_pm_list):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee6299",
   "metadata": {},
   "source": [
    "# Final with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6bbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_mogp_outliers, rmses_morcgp_outliers, rmses_rcgp_outliers, rmses_pm_outliers = [], [], [], []\n",
    "nlpds_mogp_outliers, nlpds_morcgp_outliers, nlpds_rcgp_outliers, nlpds_pm_outliers = [], [], [], []\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    # Add a small jitter for numerical stability\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    # Add 5% outliers uniformly distributed in [-4, -2] ∪ [2, 4]\n",
    "    num_outliers = int(epsilon * N * D * (1 - missing_percentage))\n",
    "    # num_outliers = 0\n",
    "    indices = np.unravel_index(np.random.choice(N * D, num_outliers, replace=False), (N, D))\n",
    "    uniform_outliers = np.random.uniform(0, 1, num_outliers)\n",
    "    outlier_values = np.where(\n",
    "        uniform_outliers < 0.5,\n",
    "        np.random.uniform(3, 5, num_outliers),\n",
    "        np.random.uniform(-5, -3, num_outliers)\n",
    "    )\n",
    "    Y_train[indices] = outlier_values\n",
    "\n",
    "    outliers_per_channel = np.bincount(indices[1])\n",
    "    non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "    epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "    # MOGP\n",
    "    mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([0.2] * D), A = 2*A)\n",
    "    mogp.fit(x_train, Y_train)\n",
    "    mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "    optim_noise = mogp.noise\n",
    "    optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "    mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "    std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "    # MORCGP\n",
    "    morcgp = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp, var_morcgp = morcgp.predict(x_test)\n",
    "    std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "    # MORCGP (RCGP weights)\n",
    "    morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=epsilons)\n",
    "    morcgp_pm.fit(x_train, Y_train)\n",
    "    morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "    std_pm = np.sqrt(var_pm + morcgp_pm.noise)\n",
    "\n",
    "    # RCGP\n",
    "    mu_rcgp, std_rcgp = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "\n",
    "    for d in range(D):\n",
    "        rcgp = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "        rcgp.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "        rcgp.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "        mu_rcgp[:, d], var_rcgp = rcgp.predict(x_test)\n",
    "        std_rcgp[:, d] = np.sqrt(var_rcgp + rcgp.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_mogp = calculate_rmse(Y_test, mu_mogp)\n",
    "    rmse_morcgp = calculate_rmse(Y_test, mu_morcgp)\n",
    "    rmse_rcgp = calculate_rmse(Y_test, mu_rcgp)\n",
    "    rmse_pm = calculate_rmse(Y_test, mu_pm)\n",
    "\n",
    "    rmses_mogp_outliers.append(rmse_mogp)\n",
    "    rmses_morcgp_outliers.append(rmse_morcgp)\n",
    "    rmses_rcgp_outliers.append(rmse_rcgp)\n",
    "    rmses_pm_outliers.append(rmse_pm)\n",
    "\n",
    "    nlpd_mogp = nlpd(Y_test, mu_mogp, std_mogp**2)\n",
    "    nlpd_morcgp = nlpd(Y_test, mu_morcgp, std_morcgp**2)\n",
    "    nlpd_rcgp = nlpd(Y_test, mu_rcgp, std_rcgp**2)\n",
    "    nlpd_pm = nlpd(Y_test, mu_pm, std_pm**2)\n",
    "\n",
    "    nlpds_mogp_outliers.append(nlpd_mogp)\n",
    "    nlpds_morcgp_outliers.append(nlpd_morcgp)\n",
    "    nlpds_rcgp_outliers.append(nlpd_rcgp)\n",
    "    nlpds_pm_outliers.append(nlpd_pm)\n",
    "\n",
    "print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "print(f'RMSE RCGP: {np.mean(rmses_rcgp):.4f} ± {np.std(rmses_rcgp):.4f}')\n",
    "print(f'RMSE MORCGP (PM): {np.mean(rmses_pm):.4f} ± {np.std(rmses_pm):.4f}')\n",
    "\n",
    "print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "print(f'NLPD RCGP: {np.mean(nlpds_rcgp):.4f} ± {np.std(nlpds_rcgp):.4f}')\n",
    "print(f'NLPD MORCGP (PM): {np.mean(nlpds_pm):.4f} ± {np.std(nlpds_pm):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_mogp_outliers_list = [x.item() for x in rmses_mogp_outliers]\n",
    "rmses_morcgp_outliers_list = [x.item() for x in rmses_morcgp_outliers]\n",
    "rmses_rcgp_outliers_list = [x.item() for x in rmses_rcgp_outliers]\n",
    "rmses_pm_outliers_list = [x.item() for x in rmses_pm_outliers]\n",
    "\n",
    "nlpds_mogp_outliers_list = [x.item() for x in nlpds_mogp_outliers]\n",
    "nlpds_morcgp_outliers_list = [x.item() for x in nlpds_morcgp_outliers]\n",
    "nlpds_rcgp_outliers_list = [x.item() for x in nlpds_rcgp_outliers]\n",
    "nlpds_pm_outliers_list = [x.item() for x in nlpds_pm_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11767a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE MOGP: {np.mean(rmses_mogp_outliers_list):.3f} ± {np.std(rmses_mogp_outliers_list):.3f}')\n",
    "print(f'RMSE MORCGP: {np.mean(rmses_morcgp_outliers_list):.3f} ± {np.std(rmses_morcgp_outliers_list):.3f}')\n",
    "print(f'RMSE RCGP: {np.mean(rmses_rcgp_outliers_list):.3f} ± {np.std(rmses_rcgp_outliers_list):.3f}')\n",
    "print(f'RMSE MORCGP (PM): {np.mean(rmses_pm_outliers_list):.3f} ± {np.std(rmses_pm_outliers_list):.3f}')\n",
    "\n",
    "print(f'NLPD MOGP: {np.mean(nlpds_mogp_outliers_list):.3f} ± {np.std(nlpds_mogp_outliers_list):.3f}')\n",
    "print(f'NLPD MORCGP: {np.mean(nlpds_morcgp_outliers_list):.3f} ± {np.std(nlpds_morcgp_outliers_list):.3f}')\n",
    "print(f'NLPD RCGP: {np.mean(nlpds_rcgp_outliers_list):.3f} ± {np.std(nlpds_rcgp_outliers_list):.3f}')\n",
    "print(f'NLPD MORCGP (PM): {np.mean(nlpds_pm_outliers_list):.3f} ± {np.std(nlpds_pm_outliers_list):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6edac6",
   "metadata": {},
   "source": [
    "# Robust hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ee472",
   "metadata": {},
   "source": [
    "## MORCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_weighted_outliers, rmses_unweighted_outliers = [], []\n",
    "nlpds_weighted_outliers, nlpds_unweighted_outliers = [], []\n",
    "\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    num_outliers = int(epsilon * N * D * (1 - missing_percentage))\n",
    "    uniform_outliers = np.random.uniform(0, 1, num_outliers)\n",
    "    outlier_values = np.where(\n",
    "        uniform_outliers < 0.5,\n",
    "        np.random.uniform(3, 5, num_outliers),\n",
    "        np.random.uniform(-5, -3, num_outliers)\n",
    "    )\n",
    "    Y_train[indices] = outlier_values\n",
    "\n",
    "    outliers_per_channel = np.bincount(indices[1])\n",
    "    non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "    epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "    # MOGP\n",
    "    mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([0.2] * D), A = 2*A)\n",
    "    mogp.fit(x_train, Y_train)\n",
    "    mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "    optim_noise = mogp.noise\n",
    "    optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "    # mu_mogp, var_mogp = mogp.predict(x_test)\n",
    "    # std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "    # MORCGP (weighted)\n",
    "    morcgp_weighted = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp_weighted.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    morcgp_weighted.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp_weighted, var_morcgp_weighted = morcgp_weighted.predict(x_test)\n",
    "    std_morcgp_weighted = np.sqrt(var_morcgp_weighted + morcgp_weighted.noise)\n",
    "\n",
    "    # MORCGP (unweighted)\n",
    "    morcgp_unweighted = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp_unweighted.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    morcgp_unweighted.optimize_loo_cv(weighted=False, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp_unweighted, var_morcgp_unweighted = morcgp_unweighted.predict(x_test)\n",
    "    std_morcgp_unweighted = np.sqrt(var_morcgp_unweighted + morcgp_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_weighted = calculate_rmse(Y_test, mu_morcgp_weighted)\n",
    "    rmse_unweighted = calculate_rmse(Y_test, mu_morcgp_unweighted)\n",
    "\n",
    "    rmses_weighted_outliers.append(rmse_weighted)\n",
    "    rmses_unweighted_outliers.append(rmse_unweighted)\n",
    "\n",
    "    nlpd_weighted = nlpd(Y_test, mu_morcgp_weighted, std_morcgp_weighted**2)\n",
    "    nlpd_unweighted = nlpd(Y_test, mu_morcgp_unweighted, std_morcgp_unweighted**2)\n",
    "\n",
    "    nlpds_weighted_outliers.append(nlpd_weighted)\n",
    "    nlpds_unweighted_outliers.append(nlpd_unweighted)\n",
    "\n",
    "print(f'RMSE WEIGHTED (outliers): {np.mean(rmses_weighted_outliers):.4f} ± {np.std(rmses_weighted_outliers):.4f}')\n",
    "print(f'RMSE UNWEIGHTED (outliers): {np.mean(rmses_unweighted_outliers):.4f} ± {np.std(rmses_unweighted_outliers):.4f}')\n",
    "\n",
    "print(f'NLPD WEIGHTED (outliers): {np.mean(nlpds_weighted_outliers):.4f} ± {np.std(nlpds_weighted_outliers):.4f}')\n",
    "print(f'NLPD UNWEIGHTED (outliers): {np.mean(nlpds_unweighted_outliers):.4f} ± {np.std(nlpds_unweighted_outliers):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_weighted_no_outliers, rmses_unweighted_no_outliers = [], []\n",
    "nlpds_weighted_no_outliers, nlpds_unweighted_no_outliers = [], []\n",
    "\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    # MOGP\n",
    "    mogp = MOGPRegressor(mean=0, length_scale=1.0, noise = np.array([0.2] * D), A = 2*A)\n",
    "    mogp.fit(x_train, Y_train)\n",
    "    mogp.optimize_hyperparameters(print_opt_param=False, print_iter_param=False)\n",
    "    optim_noise = mogp.noise\n",
    "    optim_B = mogp.A @ mogp.A.T\n",
    "\n",
    "    # MORCGP (weighted)\n",
    "    morcgp_weighted = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp_weighted.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    morcgp_weighted.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp_weighted, var_morcgp_weighted = morcgp_weighted.predict(x_test)\n",
    "    std_morcgp_weighted = np.sqrt(var_morcgp_weighted + morcgp_weighted.noise)\n",
    "\n",
    "    # MORCGP (unweighted)\n",
    "    morcgp_unweighted = MORCGPRegressor_fixed_weights(mean = 0, length_scale=lengthscale, noise = np.array([0.2]*D), A=A)\n",
    "    initial_predictive_mean, initial_predictive_variances = morcgp_unweighted.fit(x_train, Y_train, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "    morcgp_unweighted.optimize_loo_cv(weighted=False, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "    mu_morcgp_unweighted, var_morcgp_unweighted = morcgp_unweighted.predict(x_test)\n",
    "    std_morcgp_unweighted = np.sqrt(var_morcgp_unweighted + morcgp_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_weighted = calculate_rmse(Y_test, mu_morcgp_weighted)\n",
    "    rmse_unweighted = calculate_rmse(Y_test, mu_morcgp_unweighted)\n",
    "\n",
    "    rmses_weighted_no_outliers.append(rmse_weighted)\n",
    "    rmses_unweighted_no_outliers.append(rmse_unweighted)\n",
    "\n",
    "    nlpd_weighted = nlpd(Y_test, mu_morcgp_weighted, std_morcgp_weighted**2)\n",
    "    nlpd_unweighted = nlpd(Y_test, mu_morcgp_unweighted, std_morcgp_unweighted**2)\n",
    "\n",
    "    nlpds_weighted_no_outliers.append(nlpd_weighted)\n",
    "    nlpds_unweighted_no_outliers.append(nlpd_unweighted)\n",
    "\n",
    "print(f'RMSE WEIGHTED (no outliers): {np.mean(rmses_weighted_no_outliers):.4f} ± {np.std(rmses_weighted_no_outliers):.4f}')\n",
    "print(f'RMSE UNWEIGHTED (no outliers): {np.mean(rmses_unweighted_no_outliers):.4f} ± {np.std(rmses_unweighted_no_outliers):.4f}')\n",
    "\n",
    "print(f'NLPD WEIGHTED (no outliers): {np.mean(nlpds_weighted_no_outliers):.4f} ± {np.std(nlpds_weighted_no_outliers):.4f}')\n",
    "print(f'NLPD UNWEIGHTED (no outliers): {np.mean(nlpds_unweighted_no_outliers):.4f} ± {np.std(nlpds_unweighted_no_outliers):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e1077",
   "metadata": {},
   "source": [
    "## RCGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fad606",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_rcgp_weighted_outliers, rmses_rcgp_unweighted_outliers  = [], []\n",
    "nlpds_rcgp_weighted_outliers, nlpds_rcgp_unweighted_outliers = [], []\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    num_outliers = int(epsilon * N * D * (1 - missing_percentage))\n",
    "    indices = np.unravel_index(np.random.choice(N * D, num_outliers, replace=False), (N, D))\n",
    "    uniform_outliers = np.random.uniform(0, 1, num_outliers)\n",
    "    outlier_values = np.where(\n",
    "        uniform_outliers < 0.5,\n",
    "        np.random.uniform(3, 5, num_outliers),\n",
    "        np.random.uniform(-5, -3, num_outliers)\n",
    "    )\n",
    "    Y_train[indices] = outlier_values\n",
    "\n",
    "    outliers_per_channel = np.bincount(indices[1])\n",
    "    non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "    epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "\n",
    "    # RCGP weighted\n",
    "    mu_rcgp_weighted, std_rcgp_weighted = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "    for d in range(D):\n",
    "        rcgp_weighted = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "        rcgp_weighted.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "        rcgp_weighted.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=True)\n",
    "        mu_rcgp_weighted[:, d], var_rcgp_weighted = rcgp_weighted.predict(x_test)\n",
    "        std_rcgp_weighted[:, d] = np.sqrt(var_rcgp_weighted + rcgp_weighted.noise)\n",
    "\n",
    "    # RCGP unweighted\n",
    "    mu_rcgp_unweighted, std_rcgp_unweighted = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "    for d in range(D):\n",
    "        rcgp_unweighted = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "        rcgp_unweighted.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "        rcgp_unweighted.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "        mu_rcgp_unweighted[:, d], var_rcgp_unweighted = rcgp_unweighted.predict(x_test)\n",
    "        std_rcgp_unweighted[:, d] = np.sqrt(var_rcgp_unweighted + rcgp_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_rcgp_weighted = calculate_rmse(Y_test, mu_rcgp_weighted)\n",
    "    rmse_rcgp_unweighted = calculate_rmse(Y_test, mu_rcgp_unweighted)\n",
    "\n",
    "    rmses_rcgp_weighted_outliers.append(rmse_rcgp_weighted)\n",
    "    rmses_rcgp_unweighted_outliers.append(rmse_rcgp_unweighted)\n",
    "\n",
    "    nlpd_rcgp_weighted = nlpd(Y_test, mu_rcgp_weighted, std_rcgp_weighted**2)\n",
    "    nlpd_rcgp_unweighted = nlpd(Y_test, mu_rcgp_unweighted, std_rcgp_unweighted**2)\n",
    "\n",
    "    nlpds_rcgp_weighted_outliers.append(nlpd_rcgp_weighted)\n",
    "    nlpds_rcgp_unweighted_outliers.append(nlpd_rcgp_unweighted)\n",
    "\n",
    "\n",
    "print(f'RMSE WEIGHTED RCGP (outliers): {np.mean(rmses_rcgp_weighted_outliers):.4f} ± {np.std(rmses_rcgp_weighted_outliers):.4f}')\n",
    "print(f'RMSE UNWEIGHTED RCGP (outliers): {np.mean(rmses_rcgp_unweighted_outliers):.4f} ± {np.std(rmses_rcgp_unweighted_outliers):.4f}')\n",
    "\n",
    "print(f'NLPD WEIGHTED RCGP (outliers): {np.mean(nlpds_rcgp_weighted_outliers):.4f} ± {np.std(nlpds_rcgp_weighted_outliers):.4f}')\n",
    "print(f'NLPD UNWEIGHTED RCGP (outliers): {np.mean(nlpds_rcgp_unweighted_outliers):.4f} ± {np.std(nlpds_rcgp_unweighted_outliers):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_rcgp_weighted_no_outliers, rmses_rcgp_unweighted_no_outliers  = [], []\n",
    "nlpds_rcgp_weighted_no_outliers, nlpds_rcgp_unweighted_no_outliers = [], []\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    # RCGP weighted\n",
    "    mu_rcgp_weighted, std_rcgp_weighted = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "    for d in range(D):\n",
    "        rcgp_weighted = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "        rcgp_weighted.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "        rcgp_weighted.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=True)\n",
    "        mu_rcgp_weighted[:, d], var_rcgp_weighted = rcgp_weighted.predict(x_test)\n",
    "        std_rcgp_weighted[:, d] = np.sqrt(var_rcgp_weighted + rcgp_weighted.noise)\n",
    "\n",
    "    # RCGP unweighted\n",
    "    mu_rcgp_unweighted, std_rcgp_unweighted = np.full_like(Y_test, np.nan), np.full_like(Y_test, np.nan)\n",
    "    for d in range(D):\n",
    "        rcgp_unweighted = RCGPRegressor(mean=prior_mean, length_scale=lengthscale, rbf_variance=rbf_variance, noise=noise_var, epsilon=epsilon)\n",
    "        rcgp_unweighted.fit(x_train[~np.isnan(Y_train[:, d])], Y_train[:, d][~np.isnan(Y_train[:, d])].reshape(-1, 1))\n",
    "        rcgp_unweighted.optimize_loo_cv(print_opt_param=False, print_iter_param=False, weighted=False)\n",
    "        mu_rcgp_unweighted[:, d], var_rcgp_unweighted = rcgp_unweighted.predict(x_test)\n",
    "        std_rcgp_unweighted[:, d] = np.sqrt(var_rcgp_unweighted + rcgp_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_rcgp_weighted = calculate_rmse(Y_test, mu_rcgp_weighted)\n",
    "    rmse_rcgp_unweighted = calculate_rmse(Y_test, mu_rcgp_unweighted)\n",
    "\n",
    "    rmses_rcgp_weighted_no_outliers.append(rmse_rcgp_weighted)\n",
    "    rmses_rcgp_unweighted_no_outliers.append(rmse_rcgp_unweighted)\n",
    "\n",
    "    nlpd_rcgp_weighted = nlpd(Y_test, mu_rcgp_weighted, std_rcgp_weighted**2)\n",
    "    nlpd_rcgp_unweighted = nlpd(Y_test, mu_rcgp_unweighted, std_rcgp_unweighted**2)\n",
    "\n",
    "    nlpds_rcgp_weighted_no_outliers.append(nlpd_rcgp_weighted)\n",
    "    nlpds_rcgp_unweighted_no_outliers.append(nlpd_rcgp_unweighted)\n",
    "\n",
    "\n",
    "print(f'RMSE WEIGHTED RCGP (outliers): {np.mean(rmses_rcgp_weighted_no_outliers):.4f} ± {np.std(rmses_rcgp_weighted_no_outliers):.4f}')\n",
    "print(f'RMSE UNWEIGHTED RCGP (outliers): {np.mean(rmses_rcgp_unweighted_no_outliers):.4f} ± {np.std(rmses_rcgp_unweighted_no_outliers):.4f}')\n",
    "\n",
    "print(f'NLPD WEIGHTED RCGP (outliers): {np.mean(nlpds_rcgp_weighted_no_outliers):.4f} ± {np.std(nlpds_rcgp_weighted_no_outliers):.4f}')\n",
    "print(f'NLPD UNWEIGHTED RCGP (outliers): {np.mean(nlpds_rcgp_unweighted_no_outliers):.4f} ± {np.std(nlpds_rcgp_unweighted_no_outliers):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc254b8",
   "metadata": {},
   "source": [
    "## MORCGP (RCGP weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_pm_weighted_outliers, rmses_pm_unweighted_outliers= [], []\n",
    "nlpds_pm_weighted_outliers, nlpds_pm_unweighted_outliers = [], []\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    num_outliers = int(epsilon * N * D * (1 - missing_percentage))\n",
    "    indices = np.unravel_index(np.random.choice(N * D, num_outliers, replace=False), (N, D))\n",
    "    uniform_outliers = np.random.uniform(0, 1, num_outliers)\n",
    "    outlier_values = np.where(\n",
    "        uniform_outliers < 0.5,\n",
    "        np.random.uniform(3, 5, num_outliers),\n",
    "        np.random.uniform(-5, -3, num_outliers)\n",
    "    )\n",
    "    Y_train[indices] = outlier_values\n",
    "\n",
    "    outliers_per_channel = np.bincount(indices[1])\n",
    "    non_nan_counts = np.sum(~np.isnan(Y_train), axis=0)\n",
    "    epsilons = outliers_per_channel / non_nan_counts\n",
    "\n",
    "    # # Weighted MORCGP (RCGP weights)\n",
    "    # morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=epsilons)\n",
    "    # morcgp_pm.fit(x_train, Y_train)\n",
    "    # morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    # mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "    # std_pm = np.sqrt(var_pm + morcgp_pm.noise)\n",
    "\n",
    "    # Unweighted MORCGP (RCGP weights)\n",
    "    morcgp_pm_unweighted = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=epsilons)\n",
    "    morcgp_pm_unweighted.fit(x_train, Y_train)\n",
    "    morcgp_pm_unweighted.optimize_loo_cv(weighted=False, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    mu_pm_unweighted, var_pm_unweighted = morcgp_pm_unweighted.predict(x_test)\n",
    "    std_pm_unweighted = np.sqrt(var_pm_unweighted + morcgp_pm_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_pm_unweighted = calculate_rmse(Y_test, mu_pm_unweighted)\n",
    "    rmses_pm_unweighted_outliers.append(rmse_pm_unweighted)\n",
    "\n",
    "    nlpd_pm_unweighted = nlpd(Y_test, mu_pm_unweighted, std_pm_unweighted**2)\n",
    "    nlpds_pm_unweighted_outliers.append(nlpd_pm_unweighted)\n",
    "\n",
    "print(f'RMSE MORCGP unweighted (PM): {np.mean(rmses_pm_unweighted_outliers):.4f} ± {np.std(rmses_pm_unweighted_outliers):.4f}')\n",
    "print(f'NLPD MORCGP unweighted (PM): {np.mean(nlpds_pm_unweighted_outliers):.4f} ± {np.std(nlpds_pm_unweighted_outliers):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_pm_weighted_no_outliers, rmses_pm_unweighted_no_outliers= [], []\n",
    "nlpds_pm_weighted_no_outliers, nlpds_pm_unweighted_no_outliers = [], []\n",
    "\n",
    "np.random.seed(42)\n",
    "train_test_N = 300\n",
    "N, D = 100, 5\n",
    "noise_var = 0.2\n",
    "missing_percentage = 0.1 \n",
    "epsilon = 0.1\n",
    "\n",
    "lengthscale = 1.0\n",
    "rbf_variance = 1.0\n",
    "prior_mean = ConstantMean(constant=0.0)\n",
    "\n",
    "B = np.array([\n",
    "    [1.0,  0.9,  -0.7,  0.5,  -0.6],\n",
    "    [0.9,  1.0,  -0.8,  0.6,  -0.7],\n",
    "    [-0.7, -0.8,  1.0, -0.9,   0.8],\n",
    "    [0.5,  0.6,  -0.9,  1.0,  -0.85],\n",
    "    [-0.6, -0.7,  0.8, -0.85,  1.0]\n",
    "])\n",
    "A = np.linalg.cholesky(B)\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    np.random.seed(i)\n",
    "    x = np.sort(np.random.uniform(-5, 5, train_test_N)).reshape(-1, 1)\n",
    "    Kx = rbf_kernel(x, x, lengthscale=lengthscale, variance=rbf_variance)\n",
    "    K = np.kron(B, Kx)\n",
    "\n",
    "    L = cholesky(K + 1e-6*np.eye(D*train_test_N), lower=True)\n",
    "\n",
    "    f_samples = L @ np.random.randn(D*train_test_N)\n",
    "    F = f_samples.reshape(D, train_test_N).T\n",
    "    Y = F + np.random.normal(0, noise_var, F.shape)\n",
    "\n",
    "    x_train, Y_train, x_test, Y_test = train_test_split_random(x, Y, N)\n",
    "    Y_train = introduce_missing_values(Y_train, missing_percentage)\n",
    "\n",
    "    # # Weighted MORCGP (RCGP weights)\n",
    "    # morcgp_pm = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=epsilons)\n",
    "    # morcgp_pm.fit(x_train, Y_train)\n",
    "    # morcgp_pm.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    # mu_pm, var_pm = morcgp_pm.predict(x_test)\n",
    "    # std_pm = np.sqrt(var_pm + morcgp_pm.noise)\n",
    "\n",
    "    # Unweighted MORCGP (RCGP weights)\n",
    "    morcgp_pm_unweighted = MORCGPRegressor_PM(mean=0, length_scale=lengthscale, noise=np.array([0.2]*D), A=A, epsilons=np.array([0]*D))\n",
    "    morcgp_pm_unweighted.fit(x_train, Y_train)\n",
    "    morcgp_pm_unweighted.optimize_loo_cv(weighted=False, print_opt_param = False, print_iter_param=False)\n",
    "\n",
    "    mu_pm_unweighted, var_pm_unweighted = morcgp_pm_unweighted.predict(x_test)\n",
    "    std_pm_unweighted = np.sqrt(var_pm_unweighted + morcgp_pm_unweighted.noise)\n",
    "\n",
    "    # Performance metrics\n",
    "    rmse_pm_unweighted = calculate_rmse(Y_test, mu_pm_unweighted)\n",
    "    rmses_pm_unweighted_no_outliers.append(rmse_pm_unweighted)\n",
    "\n",
    "    nlpd_pm_unweighted = nlpd(Y_test, mu_pm_unweighted, std_pm_unweighted**2)\n",
    "    nlpds_pm_unweighted_no_outliers.append(nlpd_pm_unweighted)\n",
    "\n",
    "print(f'RMSE MORCGP unweighted (PM): {np.mean(rmses_pm_unweighted_no_outliers):.4f} ± {np.std(rmses_pm_unweighted_no_outliers):.4f}')\n",
    "print(f'NLPD MORCGP unweighted (PM): {np.mean(nlpds_pm_unweighted_no_outliers):.4f} ± {np.std(nlpds_pm_unweighted_no_outliers):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
