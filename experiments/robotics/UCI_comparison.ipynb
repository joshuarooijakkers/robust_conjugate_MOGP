{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1c3652",
   "metadata": {},
   "source": [
    "# Import packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3ff278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "from gpflow.optimizers import Scipy\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor, MORCGPRegressor, MOGPRegressor_NC, MORCGPRegressor_NC, MORCGPRegressor_NC_fixed_weights, MORCGPRegressor_fixed_weights, MORCGPRegressor_PM, MORCGP, MORCGP_shared_noise\n",
    "from rcgp.rcgp import RCGPRegressor\n",
    "from rcgp.kernels import ConstantMean, RBFKernel, SineMean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import MinCovDet\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 28,         \n",
    "    'axes.labelsize': 28,    \n",
    "    'axes.titlesize': 30,      # <-- Add this line for title size\n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 24,\n",
    "    'lines.linewidth': 5,    \n",
    "    'lines.markersize': 6   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd95837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A(d, r=1, base_strength=1.0, noise_level=0.1, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    shared_component = base_strength * np.ones((d, r))\n",
    "    noise = noise_level * np.random.randn(d, r)\n",
    "    A = shared_component + noise\n",
    "    return A\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def nlpd(Y_true, mu_pred, var_pred):\n",
    "    epsilon = 1e-10\n",
    "    var_pred = np.maximum(var_pred, epsilon)\n",
    "    \n",
    "    nlpd_values = 0.5 * np.log(2 * np.pi * var_pred) + ((Y_true - mu_pred) ** 2) / (2 * var_pred)\n",
    "    \n",
    "    return np.mean(nlpd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22e9f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "\n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "\n",
    "    signs = np.random.choice([-1, 1], size=num_outliers)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers) * signs\n",
    "\n",
    "    Y_outliers[row_indices, 0] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def asymmetric_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "    \n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers)\n",
    "\n",
    "    Y_outliers[row_indices, 0] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def focused_outliers_c1(X, Y, percent_outliers, y_value, perturbation=0.1):\n",
    "    def mad(X):\n",
    "        medians = np.median(X, axis=0)\n",
    "        deviations = np.abs(X - medians)\n",
    "        return np.median(deviations, axis=0)\n",
    "\n",
    "    X = X.copy()\n",
    "    Y = Y.copy()\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    n_outliers = int(n_samples * percent_outliers)\n",
    "\n",
    "    # Indices of outliers\n",
    "    indices = np.random.choice(n_samples, size=n_outliers, replace=False)\n",
    "\n",
    "    medians_2d = np.tile(np.median(X, axis=0), (n_outliers, 1))\n",
    "\n",
    "    def mad(X, axis=0):\n",
    "        \"\"\"Compute Median Absolute Deviation (MAD)\"\"\"\n",
    "        med = np.median(X, axis=axis)\n",
    "        return np.median(np.abs(X - med), axis=axis)\n",
    "\n",
    "    mads = mad(X)\n",
    "    mads_2d = np.tile(mads, (n_outliers, 1))\n",
    "\n",
    "    u = np.random.uniform(0, perturbation, size=medians_2d.shape)\n",
    "    X_outliers = medians_2d + u * mads_2d\n",
    "\n",
    "    # Create a 1D array of size n_outliers with all elements = y_value\n",
    "    Y_outliers = np.full(shape=n_outliers, fill_value=y_value)\n",
    "\n",
    "    first_column = Y[:, 0]\n",
    "    median_y0 = np.median(first_column)\n",
    "    mad_y0 = np.median(np.abs(first_column - median_y0))\n",
    "    Y_mad_outliers = np.full(shape=n_outliers, fill_value=mad_y0)\n",
    "\n",
    "    # Draw u independently for each element\n",
    "    u = np.random.uniform(0, perturbation, size=Y_outliers.shape)\n",
    "\n",
    "    # Compute the perturbed Y_outliers\n",
    "    Y_outliers_perturbed = Y_outliers + u * Y_mad_outliers\n",
    "\n",
    "    # Replace rows in X at the outlier indices\n",
    "    X[indices, :] = X_outliers\n",
    "\n",
    "    # Replace the first column in Y at the outlier indices\n",
    "    Y[indices, 0] = Y_outliers_perturbed\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Generate a smooth dataset\n",
    "np.random.seed(42)  # for reproducibility\n",
    "n_samples = 100\n",
    "\n",
    "# X is 1D but we make it 2D (n_samples, 1)\n",
    "X = np.linspace(0, 10, n_samples).reshape(-1, 1)\n",
    "\n",
    "# Y depends smoothly on X, add some noise\n",
    "Y = np.sin(X) + 0.1 * np.random.randn(n_samples, 1)\n",
    "\n",
    "# Step 2: Introduce focused outliers using your function\n",
    "X_out, Y_out = focused_outliers_c1(X, Y, percent_outliers=0.1, y_value=5, perturbation=0.3)\n",
    "\n",
    "# Step 3: Plot the original and outlier dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, Y, color='blue', label='Original Data')\n",
    "plt.scatter(X_out, Y_out, color='red', label='With Outliers')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Original Dataset and Dataset with Focused Outliers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "380ba98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 5)\n",
      "Y shape: (100, 1)\n",
      "X_out shape: (100, 5)\n",
      "Y_out shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42) \n",
    "n_samples = 100 # Number of samples \n",
    "n_features = 5 # Number of features \n",
    "percent_outliers = 0.1 # 10% of samples are outliers \n",
    "y_value = 3 # Generate X as random numbers (normal distribution) \n",
    "X = np.random.randn(n_samples, n_features) # Generate Y as a linear combination of X plus some noise \n",
    "coefficients = np.random.randn(n_features) \n",
    "Y = X @ coefficients + 0.5 * np.random.randn(n_samples)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "\n",
    "X_out, Y_out = focused_outliers_c1(X, Y, 0.1, 5, perturbation=0.1)\n",
    "print('X_out shape:', X_out.shape)\n",
    "print('Y_out shape:', Y_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_multi(X, D=2):\n",
    "    \"\"\"\n",
    "    X: shape (N, input_dim) - multi-dimensional input\n",
    "    D: number of tasks\n",
    "    \"\"\"\n",
    "    N, input_dim = X.shape\n",
    "    X_multi = []\n",
    "    \n",
    "    for task in range(D):\n",
    "        # Add task index as last column\n",
    "        X_task = np.hstack([X, np.full((N, 1), task)])\n",
    "        X_multi.append(X_task)\n",
    "    \n",
    "    return np.vstack(X_multi)  # Shape: (N*D, input_dim + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c32ac7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled):\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    # --- 1. Prepare multi-task inputs ---\n",
    "    X_multi_train = make_X_multi(X_train_scaled, D=2)\n",
    "    X_multi_test = make_X_multi(X_test_scaled, D=2)\n",
    "    Y_multi_train = Y_train_scaled.reshape(-1, 1, order='F')\n",
    "    Y_multi_test = Y_test_scaled.reshape(-1, 1, order='F')\n",
    "\n",
    "    input_dim = X_train_scaled.shape[1]  # number of features\n",
    "    D = 2  # number of tasks\n",
    "\n",
    "    # --- 2. Define kernel ---\n",
    "    base_kernel = gpflow.kernels.RBF(\n",
    "        lengthscales=1.0,\n",
    "        variance=0.1,\n",
    "        active_dims=list(range(input_dim))\n",
    "    )\n",
    "\n",
    "    coregion_kernel = gpflow.kernels.Coregion(\n",
    "        output_dim=D,\n",
    "        rank=D,\n",
    "        active_dims=[input_dim]\n",
    "    )\n",
    "\n",
    "    # Fix the diagonal of coregion kernel\n",
    "    gpflow.utilities.set_trainable(coregion_kernel.kappa, False)\n",
    "    coregion_kernel.kappa.assign(tf.ones_like(coregion_kernel.kappa) * 1e-6)\n",
    "\n",
    "    # Combine kernels\n",
    "    kernel = base_kernel * coregion_kernel\n",
    "\n",
    "    # --- 3. Build exact GP model ---\n",
    "    model_gpr = gpflow.models.GPR(\n",
    "        data=(X_multi_train, Y_multi_train),\n",
    "        kernel=kernel,\n",
    "        mean_function=None\n",
    "    )\n",
    "\n",
    "    # Optionally, you can fix the base kernel variance as before\n",
    "    gpflow.utilities.set_trainable(base_kernel.variance, False)\n",
    "\n",
    "    # --- 4. Optimize hyperparameters ---\n",
    "    opt = Scipy()\n",
    "\n",
    "    def objective_closure_gpr():\n",
    "        return -model_gpr.log_marginal_likelihood()\n",
    "    try:\n",
    "        opt.minimize(objective_closure_gpr, model_gpr.trainable_variables, options=dict(maxiter=1000))\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        print(\"Try reducing maxiter or checking data shapes\")\n",
    "\n",
    "    # --- 5. Predict on test data ---\n",
    "    mean_pred_mogp, var_pred_mogp = model_gpr.predict_y(X_multi_test)\n",
    "    mu_mogp, std_mogp = mean_pred_mogp.numpy().reshape(-1, D, order='F'), np.sqrt(var_pred_mogp.numpy()).reshape(-1, D, order='F')\n",
    "\n",
    "    end_total = time.time()\n",
    "    time_mogp = end_total - start_total\n",
    "\n",
    "    rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp.reshape(-1, D, order='F'))\n",
    "    nlpd_mogp = nlpd(Y_test_scaled, mu_mogp.reshape(-1, D, order='F'), std_mogp.reshape(-1, D, order='F')**2)\n",
    "    \n",
    "    return rmse_mogp, nlpd_mogp, time_mogp\n",
    "\n",
    "\n",
    "def run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers, k=1):\n",
    "    # Measure total time\n",
    "    start_total = time.time()\n",
    "\n",
    "    mcd = MinCovDet(support_fraction=1-prop_outliers).fit(Y_train_scaled)\n",
    "    robust_covariance = mcd.covariance_\n",
    "    robust_init_A = np.linalg.cholesky(robust_covariance)\n",
    "\n",
    "    morcgp = MORCGP_shared_noise(mean=0, length_scale=1, noise_var=0.1, A=robust_init_A)\n",
    "    morcgp.fit(X_train_scaled, Y_train_scaled, epsilons=np.array([prop_outliers, 0]))\n",
    "    morcgp.optimize_loo_cv(print_opt_param=False, print_iter_objective=False, k=k, init_cov=robust_covariance, fix_weights=True)\n",
    "\n",
    "    mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "    std_morcgp = np.sqrt(var_morcgp + morcgp.noise_var)\n",
    "    end_total = time.time()\n",
    "\n",
    "    time_morcgp = end_total - start_total\n",
    "    rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "    nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "    return rmse_morcgp, nlpd_morcgp, time_morcgp\n",
    "\n",
    "def run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df):\n",
    "    # Create multi-task inputs\n",
    "    X_multi_train = make_X_multi(X_train_scaled, D=2)\n",
    "    X_multi_test = make_X_multi(X_test_scaled, D=2)\n",
    "    Y_multi_train = Y_train_scaled.reshape(-1, 1, order='F')\n",
    "    Y_multi_test = Y_test_scaled.reshape(-1, 1, order='F')\n",
    "\n",
    "    input_dim = X_train_scaled.shape[1]  # This is the key fix!\n",
    "    N = X_train_scaled.shape[0]\n",
    "    D = 2\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    base_kernel = gpflow.kernels.RBF(\n",
    "        lengthscales=1.0, \n",
    "        variance=0.1, \n",
    "        active_dims=list(range(input_dim)) ,\n",
    "    )\n",
    "\n",
    "    coregion_kernel = gpflow.kernels.Coregion(\n",
    "        output_dim=D, \n",
    "        rank=D, \n",
    "        active_dims=[input_dim]  \n",
    "    )\n",
    "\n",
    "    gpflow.utilities.set_trainable(coregion_kernel.kappa, False)\n",
    "    coregion_kernel.kappa.assign(tf.ones_like(coregion_kernel.kappa) * 1e-6)\n",
    "\n",
    "    kernel = base_kernel * coregion_kernel\n",
    "\n",
    "    likelihood_vgp = gpflow.likelihoods.StudentT(df=df)\n",
    "    # gpflow.utilities.set_trainable(likelihood_vgp.scale, False)\n",
    "    model_vgp = gpflow.models.VGP(\n",
    "        data=(X_multi_train, Y_multi_train),\n",
    "        kernel=kernel,\n",
    "        likelihood=likelihood_vgp\n",
    "    )\n",
    "\n",
    "    opt = Scipy()\n",
    "    def objective_closure_vgp():\n",
    "        return -model_vgp.maximum_log_likelihood_objective()\n",
    "\n",
    "    try:\n",
    "        opt.minimize(objective_closure_vgp, model_vgp.trainable_variables, options=dict(maxiter=1000))\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        print(\"Try reducing maxiter or checking data shapes\")\n",
    "\n",
    "    mean_pred_tmogp, var_pred_tmogp = model_vgp.predict_y(X_multi_test)\n",
    "    mu_tmogp, std_tmogp = mean_pred_tmogp.numpy().reshape(-1, D, order='F'), np.sqrt(var_pred_tmogp.numpy()).reshape(-1, D, order='F')\n",
    "    end_total = time.time()\n",
    "\n",
    "    time_tmogp = end_total - start_total\n",
    "    rmse_tmogp = calculate_rmse(Y_test_scaled, mu_tmogp.reshape(-1, D, order='F'))\n",
    "    nlpd_tmogp = nlpd(Y_test_scaled, mu_tmogp.reshape(-1, D, order='F'), std_tmogp.reshape(-1, D, order='F')**2)\n",
    "    \n",
    "    return rmse_tmogp, nlpd_tmogp, time_tmogp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0c8674a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'\n",
    "\n",
    "# Read Excel file directly from the URL\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "# Extract covariates X (columns X1 to X8)\n",
    "X = df.loc[:, 'X1':'X8'].to_numpy()\n",
    "\n",
    "# Extract target variables Y (columns Y1 and Y2)\n",
    "Y = df.loc[:, ['Y1', 'Y2']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4b9d3",
   "metadata": {},
   "source": [
    "# No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f04b45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (576, 8)\n",
      "X_test shape: (192, 8)\n",
      "Y_train shape: (576, 2)\n",
      "Y_test shape: (192, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets (default test size = 25%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Y_train shape:\", Y_train_scaled.shape)\n",
    "print(\"Y_test shape:\", Y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af867311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [08:04<00:00, 484.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MOGP: 0.1424 ± 0.0000\n",
      "NLPD MOGP: -0.5311 ± 0.0000\n",
      "Time MOGP: 15.8279 ± 0.0000\n",
      "RMSE MORCGP: 0.1251 ± 0.0000\n",
      "NLPD MORCGP: -0.8502 ± 0.0000\n",
      "Time MORCGP: 61.0663 ± 0.0000\n",
      "RMSE t-MOGP: 0.1686 ± 0.0000\n",
      "NLPD t-MOGP: -0.3568 ± 0.0000\n",
      "Time t-MOGP: 407.1430 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0\n",
    "num_seeds = 1\n",
    "\n",
    "run_mogp = True\n",
    "run_morcgp = True\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    # Split data into train and test sets (default test size = 25%)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled)\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d493a",
   "metadata": {},
   "source": [
    "# Uniform outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b21f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [07:33<00:00, 453.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MOGP: 0.9396 ± 0.0000\n",
      "NLPD MOGP: 1.6614 ± 0.0000\n",
      "Time MOGP: 5.3925 ± 0.0000\n",
      "RMSE MORCGP: 0.1588 ± 0.0000\n",
      "NLPD MORCGP: -0.2128 ± 0.0000\n",
      "Time MORCGP: 89.8483 ± 0.0000\n",
      "RMSE t-MOGP: 0.1798 ± 0.0000\n",
      "NLPD t-MOGP: -0.1059 ± 0.0000\n",
      "Time t-MOGP: 357.9580 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 1\n",
    "\n",
    "run_mogp = True\n",
    "run_morcgp = True\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    # Split data into train and test sets (default test size = 25%)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    Y_train_scaled = uniform_outliers_c1(Y=Y_train_scaled, percent_outliers=prop_outliers, start=6, end=9)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled)\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66bed1",
   "metadata": {},
   "source": [
    "# Asymmetric outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14e796e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [14:19<00:00, 429.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MOGP: 0.9901 ± 0.0026\n",
      "NLPD MOGP: 1.6316 ± 0.0072\n",
      "Time MOGP: 6.9231 ± 2.5147\n",
      "RMSE MORCGP: 0.1473 ± 0.0047\n",
      "NLPD MORCGP: -0.2885 ± 0.0435\n",
      "Time MORCGP: 55.2301 ± 34.6966\n",
      "RMSE t-MOGP: 0.1953 ± 0.0075\n",
      "NLPD t-MOGP: -0.0750 ± 0.0043\n",
      "Time t-MOGP: 367.5393 ± 16.9574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 2\n",
    "\n",
    "run_mogp = True\n",
    "run_morcgp = True\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    # Split data into train and test sets (default test size = 25%)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    Y_train_scaled = asymmetric_outliers_c1(Y=Y_train_scaled, percent_outliers=prop_outliers, start=6, end=9)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled)\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34ecf120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94723653 0.90867649]\n",
      " [0.90867649 0.90533608]]\n",
      "Optimized length_scale: 1.1465\n",
      "Optimized noise_var: 0.030009044314197594\n",
      "Optimized A: [[ 1.26725414 -0.10627154]\n",
      " [ 0.99090882  0.28129842]]\n",
      "Optimized B: \n",
      "[[1.61722669 1.22583928]\n",
      " [1.22583928 1.06102909]]\n",
      "Total runtime: 59.0478 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure total time\n",
    "start_total = time.time()\n",
    "\n",
    "prop_outliers = 0.1\n",
    "\n",
    "mcd = MinCovDet(support_fraction=1-prop_outliers).fit(Y_train_scaled)\n",
    "robust_covariance = mcd.covariance_\n",
    "print(robust_covariance)\n",
    "robust_init_A = np.linalg.cholesky(robust_covariance)\n",
    "\n",
    "morcgp = MORCGP_shared_noise(mean=0, length_scale=1, noise_var=0.1, A=robust_init_A)\n",
    "morcgp.fit(X_train_scaled, Y_train_scaled, epsilons=np.array([prop_outliers, 0]))\n",
    "init_gamma, init_c, gamma, c = morcgp.optimize_loo_cv(print_opt_param=True, print_iter_objective=False, k=2, init_cov=robust_covariance, fix_weights=True)\n",
    "\n",
    "mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise_var)\n",
    "\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c61e83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MORCGP: 0.15972676319172377\n",
      "NLPD MORCGP: -0.1996795777671061\n"
     ]
    }
   ],
   "source": [
    "rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "\n",
    "nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24022cf5",
   "metadata": {},
   "source": [
    "# Focused outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ac57997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [07:32<00:00, 452.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE MOGP: 0.5196 ± 0.0000\n",
      "NLPD MOGP: 0.7991 ± 0.0000\n",
      "Time MOGP: 10.7921 ± 0.0000\n",
      "RMSE MORCGP: 0.1456 ± 0.0000\n",
      "NLPD MORCGP: -0.1450 ± 0.0000\n",
      "Time MORCGP: 108.6249 ± 0.0000\n",
      "RMSE t-MOGP: 0.2741 ± 0.0000\n",
      "NLPD t-MOGP: 0.2311 ± 0.0000\n",
      "Time t-MOGP: 332.9594 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 1\n",
    "\n",
    "run_mogp = True\n",
    "run_morcgp = True\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    # Split data into train and test sets (default test size = 25%)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    X_train_scaled, Y_train_scaled = focused_outliers_c1(X=X_train_scaled, Y=Y_train_scaled, percent_outliers=prop_outliers, y_value=5, perturbation=0.1)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled)\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
