{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3156f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor, MORCGPRegressor, MOGPRegressor_NC, MORCGPRegressor_NC, MORCGPRegressor_NC_fixed_weights, MORCGPRegressor_fixed_weights, MORCGPRegressor_PM\n",
    "from rcgp.rcgp import RCGPRegressor\n",
    "from rcgp.kernels import ConstantMean, RBFKernel, SineMean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 28,         \n",
    "    'axes.labelsize': 28,    \n",
    "    'axes.titlesize': 30,      # <-- Add this line for title size\n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 24,\n",
    "    'lines.linewidth': 5,    \n",
    "    'lines.markersize': 6   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A(d, r=1, base_strength=1.0, noise_level=0.1, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    shared_component = base_strength * np.ones((d, r))\n",
    "    noise = noise_level * np.random.randn(d, r)\n",
    "    A = shared_component + noise\n",
    "    return A\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def nlpd(Y_true, mu_pred, var_pred):\n",
    "    epsilon = 1e-10\n",
    "    var_pred = np.maximum(var_pred, epsilon)\n",
    "    \n",
    "    nlpd_values = 0.5 * np.log(2 * np.pi * var_pred) + ((Y_true - mu_pred) ** 2) / (2 * var_pred)\n",
    "    \n",
    "    return np.mean(nlpd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_outliers(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "\n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N * D\n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    indices = np.unravel_index(\n",
    "        np.random.choice(total_elements, num_outliers, replace=False),\n",
    "        (N, D)\n",
    "    )\n",
    "\n",
    "    signs = np.random.choice([-1, 1], size=num_outliers)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers) * signs\n",
    "\n",
    "    Y_outliers[indices] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def uniform_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "\n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "    col_indices = np.zeros(num_outliers, dtype=int) \n",
    "\n",
    "    signs = np.random.choice([-1, 1], size=num_outliers)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers) * signs\n",
    "\n",
    "    Y_outliers[row_indices, col_indices] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def asymmetric_outliers(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "\n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N * D\n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    indices = np.unravel_index(\n",
    "        np.random.choice(total_elements, num_outliers, replace=False),\n",
    "        (N, D)\n",
    "    )\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers)\n",
    "\n",
    "    Y_outliers[indices] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def asymmetric_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "    \n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "    col_indices = np.zeros(num_outliers, dtype=int) \n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers)\n",
    "\n",
    "    Y_outliers[row_indices, col_indices] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def focused_outliers(X, Y, percent_outliers, y_value):\n",
    "    X = X.copy()\n",
    "    Y = Y.copy()\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    n_outliers = int(n_samples * percent_outliers)\n",
    "\n",
    "    indices = np.random.choice(n_samples, size=n_outliers, replace=False)\n",
    "    medians = np.median(X, axis=0)\n",
    "\n",
    "    for idx in indices:\n",
    "        Y[idx, 0] = y_value\n",
    "        X[idx] = medians\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325fd12",
   "metadata": {},
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_icm_rbf(X, *, lengthscale=1.0, B=None, noise_variance=0.0, jitter=1e-6, random_state=None):\n",
    "\n",
    "    X = np.asarray(X, dtype=float).reshape(-1, 1)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if B is None:\n",
    "        B = np.array([[1.0, 0.7],\n",
    "                      [0.7, 1.0]])\n",
    "\n",
    "    sq_dists = (X - X.T) ** 2\n",
    "    Kx = np.exp(-0.5 * sq_dists / lengthscale ** 2)      \n",
    "\n",
    "    K = np.kron(B, Kx)                                   \n",
    "    K += jitter * np.eye(K.shape[0])                      \n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    y = rng.multivariate_normal(np.zeros(K.shape[0]), K)   \n",
    "    y = y.reshape(2, n).T                              \n",
    "\n",
    "    noise_variance = np.asarray(noise_variance, dtype=float)\n",
    "    if noise_variance.ndim == 0:\n",
    "        y += rng.normal(scale=np.sqrt(noise_variance), size=y.shape)\n",
    "    elif noise_variance.ndim == 1 and noise_variance.shape[0] == 2:\n",
    "        scales = np.sqrt(noise_variance)[None, :]        \n",
    "        y += rng.normal(scale=scales, size=y.shape)\n",
    "    else:\n",
    "        raise ValueError(\"noise_variance must be a scalar or length‑2 array\")\n",
    "\n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "N = 100\n",
    "D = 2\n",
    "\n",
    "X = np.linspace(0.0, 10, N)\n",
    "Y = sample_icm_rbf(X, lengthscale=1, noise_variance=0.05, random_state=41)\n",
    "\n",
    "# Outliers\n",
    "outlier_range = np.where((X >= 4) & (X <= 5))[0]\n",
    "outlier_indices = np.random.choice(outlier_range, int(10), replace=False)\n",
    "Y[outlier_indices, 0] = np.random.normal(loc=-3, scale=0.5, size=outlier_indices.shape[0])\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(X.flatten(), Y[:, i], 'o', label=f'Output {i+1}')\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c830333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mogp = MOGPRegressor(mean = 0, length_scale=0.1, noise = noise, A=A)\n",
    "mogp = MOGPRegressor_NC(mean = 0, length_scale=0.1, noise = 0.04, A=np.array([[1, 0.7], [0.7, 1]]))\n",
    "mogp.fit(X.reshape(-1,1), Y)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "\n",
    "# Predict on test points\n",
    "x_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "mu, var = mogp.predict(x_test)\n",
    "std = np.sqrt(var + mogp.noise)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].plot(X.flatten(), Y[:, i], 'k*', label=f'Observed Data')\n",
    "    axs[i].plot(x_test.flatten(), mu[:, i], 'r-', label=f'Predicted Mean')\n",
    "    axs[i].fill_between(x_test.flatten(), mu[:, i] - 2*std[:, i], mu[:, i] + 2*std[:, i], color='r', alpha=0.2, label=f'±2 Std. Dev.')\n",
    "\n",
    "    axs[i].set_title(f\"Output Function {i+1}\")\n",
    "    axs[i].set_ylim([-6, 6])\n",
    "    # axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8441e",
   "metadata": {},
   "source": [
    "# Energy Efficiency Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'\n",
    "\n",
    "# Read Excel file directly from the URL\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "# Extract covariates X (columns X1 to X8)\n",
    "X = df.loc[:, 'X1':'X8'].to_numpy()\n",
    "\n",
    "# Extract target variables Y (columns Y1 and Y2)\n",
    "Y = df.loc[:, ['Y1', 'Y2']].to_numpy()\n",
    "\n",
    "# Split data into train and test sets (default test size = 25%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41db3c6",
   "metadata": {},
   "source": [
    "## No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Y_train shape:\", Y_train_scaled.shape)\n",
    "print(\"Y_test shape:\", Y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c04c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_A = generate_A(d = 2, r = 2)\n",
    "\n",
    "# Measure total time\n",
    "start_total = time.time()\n",
    "\n",
    "mogp = MOGPRegressor_NC(mean=0, length_scale=1.67, noise=0.04, A=initial_A)\n",
    "mogp.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_lengthscale = mogp.length_scale\n",
    "optim_noise = mogp.noise\n",
    "optim_A = mogp.A\n",
    "optim_B = optim_A @ optim_A.T\n",
    "\n",
    "# Measure prediction time\n",
    "start_pred = time.time()\n",
    "mu_mogp, var_mogp = mogp.predict(X_test_scaled)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "end_pred = time.time()\n",
    "\n",
    "end_total = time.time()\n",
    "\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a563832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure total time\n",
    "start_total = time.time()\n",
    "morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_lengthscale, noise = optim_noise, A=optim_A)\n",
    "predictive_mean, predictive_variances = morcgp.fit(X_train_scaled, Y_train_scaled, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = False, print_iter_param=False, update_weights=True)\n",
    "\n",
    "start_pred = time.time()\n",
    "mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b111ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test_scaled, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822034ba",
   "metadata": {},
   "source": [
    "## Uniform outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2fd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "Y_train_scaled = uniform_outliers_c1(Y=Y_train_scaled, percent_outliers=0.1, start=2, end=3)\n",
    "\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Y_train shape:\", Y_train_scaled.shape)\n",
    "print(\"Y_test shape:\", Y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f498b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_A = generate_A(d = 2, r = 2)\n",
    "start_total = time.time()\n",
    "mogp = MOGPRegressor_NC(mean = 0, length_scale=1.67, noise = 0.04, A=initial_A)\n",
    "mogp.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "print('Fitted data')\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_lengthscale = mogp.length_scale\n",
    "optim_noise = mogp.noise\n",
    "optim_A = mogp.A\n",
    "optim_B = optim_A @ optim_A.T\n",
    "\n",
    "print('Optimized hyperparameters')\n",
    "\n",
    "# Predict on test points\n",
    "start_pred = time.time()\n",
    "mu_mogp, var_mogp = mogp.predict(X_test_scaled)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a061a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(Y_train_scaled, rowvar=False)\n",
    "print(cov_matrix)\n",
    "\n",
    "start_total = time.time()\n",
    "morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_lengthscale, noise = optim_noise, A=optim_A)\n",
    "initial_predictive_mean, initial_predictive_variances = morcgp.fit(X_train_scaled, Y_train_scaled, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "# print(predictive_mean)\n",
    "# print(predictive_variances)\n",
    "# print('Fitted data')\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=optim_lengthscale, noise=optim_noise, A=optim_A, weighted=True))\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=False, update_weights=True)\n",
    "\n",
    "\n",
    "start_pred = time.time()\n",
    "mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test_scaled, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mu_mogp', mu_mogp.reshape(-1)[:6])\n",
    "print('mu_morcgp', mu_morcgp.reshape(-1)[:6])\n",
    "print('true test', Y_test_scaled.reshape(-1)[:6])\n",
    "print('true train', Y_train_scaled.reshape(-1)[:6])\n",
    "print('init_pred_mean:', initial_predictive_mean.reshape(-1)[:6])\n",
    "print('init_pred_var:', initial_predictive_variances.reshape(-1)[:6])\n",
    "print('pred_mean:', predictive_mean.reshape(-1)[:6])\n",
    "print('pred_var:', predictive_variances.reshape(-1)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e85ed",
   "metadata": {},
   "source": [
    "## Asymmetric outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ce9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "Y_train_scaled = asymmetric_outliers_c1(Y=Y_train_scaled, percent_outliers=0.1, start=2, end=3)\n",
    "\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Y_train shape:\", Y_train_scaled.shape)\n",
    "print(\"Y_test shape:\", Y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_A = generate_A(d = 2, r = 2)\n",
    "start_total = time.time()\n",
    "mogp = MOGPRegressor_NC(mean = 0, length_scale=1.67, noise = 0.04, A=initial_A)\n",
    "mogp.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "print('Fitted data')\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_lengthscale = mogp.length_scale\n",
    "optim_noise = mogp.noise\n",
    "optim_A = mogp.A\n",
    "optim_B = optim_A @ optim_A.T\n",
    "\n",
    "print('Optimized hyperparameters')\n",
    "\n",
    "# Predict on test points\n",
    "start_pred = time.time()\n",
    "mu_mogp, var_mogp = mogp.predict(X_test_scaled)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(Y_train_scaled, rowvar=False)\n",
    "print(cov_matrix)\n",
    "\n",
    "start_total = time.time()\n",
    "morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_lengthscale, noise = optim_noise, A=optim_A)\n",
    "initial_predictive_mean, initial_predictive_variances = morcgp.fit(X_train_scaled, Y_train_scaled, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "# print(predictive_mean)\n",
    "# print(predictive_variances)\n",
    "# print('Fitted data')\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=optim_lengthscale, noise=optim_noise, A=optim_A, weighted=True))\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=False, update_weights=True)\n",
    "\n",
    "print('Optimized hyperparameters')\n",
    "\n",
    "start_pred = time.time()\n",
    "\n",
    "mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f004c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test_scaled, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421b549",
   "metadata": {},
   "source": [
    "## Focused outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "X_train_scaled, Y_train_scaled = focused_outliers(X=X_train_scaled, Y=Y_train_scaled, percent_outliers=0.1, y_value=4)\n",
    "\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Y_train shape:\", Y_train_scaled.shape)\n",
    "print(\"Y_test shape:\", Y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train_scaled[22, 0].reshape(-1))\n",
    "print(X_train_scaled[22, :].reshape(-1)[:6])\n",
    "print(Y_train_scaled[25, 0].reshape(-1))\n",
    "print(X_train_scaled[25, :].reshape(-1)[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_A = generate_A(d = 2, r = 2)\n",
    "start_total = time.time()\n",
    "mogp = MOGPRegressor_NC(mean = 0, length_scale=1.67, noise = 0.04, A=initial_A)\n",
    "mogp.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "print('Fitted data')\n",
    "\n",
    "# Optimize hyperparameters\n",
    "mogp.optimize_hyperparameters()\n",
    "optim_lengthscale = mogp.length_scale\n",
    "optim_noise = mogp.noise\n",
    "optim_A = mogp.A\n",
    "optim_B = optim_A @ optim_A.T\n",
    "\n",
    "print('Optimized hyperparameters')\n",
    "\n",
    "# Predict on test points\n",
    "start_pred = time.time()\n",
    "mu_mogp, var_mogp = mogp.predict(X_test_scaled)\n",
    "std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd34563",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(Y_train_scaled, rowvar=False)\n",
    "print(cov_matrix)\n",
    "\n",
    "start_total = time.time()\n",
    "morcgp = MORCGPRegressor_NC_fixed_weights(mean = 0, length_scale=optim_lengthscale, noise = optim_noise, A=optim_A)\n",
    "initial_predictive_mean, initial_predictive_variances = morcgp.fit(X_train_scaled, Y_train_scaled, B_weighted=optim_B, noise_weighted=optim_noise)\n",
    "# print(predictive_mean)\n",
    "# print(predictive_variances)\n",
    "# print('Fitted data')\n",
    "\n",
    "# print(morcgp.loo_cv(length_scale=optim_lengthscale, noise=optim_noise, A=optim_A, weighted=True))\n",
    "predictive_mean, predictive_variances = morcgp.optimize_loo_cv(weighted=True, print_opt_param = True, print_iter_param=False, update_weights=True)\n",
    "\n",
    "print('Optimized hyperparameters')\n",
    "\n",
    "start_pred = time.time()\n",
    "\n",
    "mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "std_morcgp = np.sqrt(var_morcgp + morcgp.noise)\n",
    "\n",
    "end_pred = time.time()\n",
    "end_total = time.time()\n",
    "print(f\"Total runtime: {end_total - start_total:.4f} seconds\")\n",
    "print(f\"Prediction runtime: {end_pred - start_pred:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp)\n",
    "rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "\n",
    "print(\"RMSE MOGP:\", rmse_mogp)\n",
    "print(\"RMSE MORCGP:\", rmse_morcgp)\n",
    "\n",
    "nlpd_mogp = nlpd(Y_test_scaled, mu_mogp, std_mogp**2)\n",
    "nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "print(\"NLPD MOGP:\", nlpd_mogp)\n",
    "print(\"NLPD MORCGP:\", nlpd_morcgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "N_test, D = Y_train_scaled.shape\n",
    "data = {\n",
    "    \"Value\": np.concatenate([Y_train_scaled.flatten(), Y_train_scaled.flatten()]),\n",
    "    \"Type\": [\"True\"] * (N_test * D) + [\"Predicted\"] * (N_test * D),\n",
    "    \"Dimension\": [f\"D{i+1}\" for i in range(D)] * N_test * 2\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=\"Dimension\", y=\"Value\", hue=\"Type\", data=df, split=True)\n",
    "plt.title(\"Violin Plot of True vs Predicted Values\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xlabel(\"Output Dimension\")\n",
    "plt.legend(title=\"Legend\")\n",
    "plt.tight_layout()\n",
    "plt.ylim(-3,6)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
