{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ff278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpflow\\versions.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "from gpflow.optimizers import Scipy\n",
    "\n",
    "from rcgp.morcgp import MOGPRegressor_NC, MORCGP_shared_noise\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import MinCovDet\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,         \n",
    "    \"font.family\": \"serif\",       \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n",
    "    'font.size': 28,         \n",
    "    'axes.labelsize': 28,    \n",
    "    'axes.titlesize': 30,    \n",
    "    'xtick.labelsize': 24,   \n",
    "    'ytick.labelsize': 24,  \n",
    "    'legend.fontsize': 24,\n",
    "    'lines.linewidth': 5,    \n",
    "    'lines.markersize': 6   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd95837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(y_true, y_pred):\n",
    "    errors = y_true - y_pred\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def nlpd(Y_true, mu_pred, var_pred):\n",
    "    epsilon = 1e-10\n",
    "    var_pred = np.maximum(var_pred, epsilon)\n",
    "    \n",
    "    nlpd_values = 0.5 * np.log(2 * np.pi * var_pred) + ((Y_true - mu_pred) ** 2) / (2 * var_pred)\n",
    "    \n",
    "    return np.mean(nlpd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e9f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "\n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "\n",
    "    signs = np.random.choice([-1, 1], size=num_outliers)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers) * signs\n",
    "\n",
    "    Y_outliers[row_indices, 0] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def asymmetric_outliers_c1(Y: np.ndarray, percent_outliers: float, start: float, end: float) -> np.ndarray:\n",
    "    if not (0 <= percent_outliers <= 1):\n",
    "        raise ValueError(\"percent_outliers must be between 0 and 1.\")\n",
    "    if start < 0 or end <= start:\n",
    "        raise ValueError(\"Invalid range: ensure 0 <= start < end.\")\n",
    "    \n",
    "    Y_outliers = Y.copy()\n",
    "    N, D = Y.shape\n",
    "    total_elements = N \n",
    "    num_outliers = int(np.round(percent_outliers * total_elements))\n",
    "\n",
    "    row_indices = np.random.choice(N, num_outliers, replace=False)\n",
    "\n",
    "    uniform_values = np.random.uniform(start, end, size=num_outliers)\n",
    "\n",
    "    Y_outliers[row_indices, 0] += uniform_values\n",
    "\n",
    "    return Y_outliers\n",
    "\n",
    "def focused_outliers_c1(X, Y, percent_outliers, y_value, perturbation=0.1):\n",
    "    def mad(X):\n",
    "        medians = np.median(X, axis=0)\n",
    "        deviations = np.abs(X - medians)\n",
    "        return np.median(deviations, axis=0)\n",
    "\n",
    "    X = X.copy()\n",
    "    Y = Y.copy()\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    n_outliers = int(n_samples * percent_outliers)\n",
    "\n",
    "    # Indices of outliers\n",
    "    indices = np.random.choice(n_samples, size=n_outliers, replace=False)\n",
    "\n",
    "    medians_2d = np.tile(np.median(X, axis=0), (n_outliers, 1))\n",
    "\n",
    "    def mad(X, axis=0):\n",
    "        \"\"\"Compute Median Absolute Deviation (MAD)\"\"\"\n",
    "        med = np.median(X, axis=axis)\n",
    "        return np.median(np.abs(X - med), axis=axis)\n",
    "\n",
    "    mads = mad(X)\n",
    "    mads_2d = np.tile(mads, (n_outliers, 1))\n",
    "\n",
    "    u = np.random.uniform(0, perturbation, size=medians_2d.shape)\n",
    "    X_outliers = medians_2d + u * mads_2d\n",
    "\n",
    "    Y_outliers = np.full(shape=n_outliers, fill_value=y_value)\n",
    "\n",
    "    first_column = Y[:, 0]\n",
    "    median_y0 = np.median(first_column)\n",
    "    mad_y0 = np.median(np.abs(first_column - median_y0))\n",
    "    Y_mad_outliers = np.full(shape=n_outliers, fill_value=mad_y0)\n",
    "\n",
    "    # Draw u independently for each element\n",
    "    u = np.random.uniform(0, perturbation, size=Y_outliers.shape)\n",
    "\n",
    "    # Compute the perturbed Y_outliers\n",
    "    Y_outliers_perturbed = Y_outliers + u * Y_mad_outliers\n",
    "\n",
    "    X[indices, :] = X_outliers\n",
    "    Y[indices, 0] = Y_outliers_perturbed\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def student_t_outliers(Y, percent_outliers, df=8, scale=5.0):\n",
    "    Y = Y.copy()\n",
    "\n",
    "    n_samples = Y.shape[0]\n",
    "    n_outliers = int(n_samples * percent_outliers)\n",
    "\n",
    "    indices = np.random.choice(n_samples, size=n_outliers, replace=False)\n",
    "\n",
    "    t_y_samples = np.random.standard_t(df=df, size=n_outliers) * scale\n",
    "\n",
    "    Y[indices, 0] += t_y_samples\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32ac7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_multi(X, D=2):\n",
    "    \"\"\"\n",
    "    X: shape (N, input_dim) - multi-dimensional input\n",
    "    D: number of tasks\n",
    "    \"\"\"\n",
    "    N, input_dim = X.shape\n",
    "    X_multi = []\n",
    "    \n",
    "    for task in range(D):\n",
    "        # Add task index as last column\n",
    "        X_task = np.hstack([X, np.full((N, 1), task)])\n",
    "        X_multi.append(X_task)\n",
    "    \n",
    "    return np.vstack(X_multi)  # Shape: (N*D, input_dim + 1)\n",
    "\n",
    "def run_MOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled):\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    X_multi_train = make_X_multi(X_train_scaled, D=2)\n",
    "    X_multi_test = make_X_multi(X_test_scaled, D=2)\n",
    "    Y_multi_train = Y_train_scaled.reshape(-1, 1, order='F')\n",
    "    Y_multi_test = Y_test_scaled.reshape(-1, 1, order='F')\n",
    "\n",
    "    input_dim = X_train_scaled.shape[1]  # number of features\n",
    "    D = 2  # number of tasks\n",
    "\n",
    "    base_kernel = gpflow.kernels.RBF(\n",
    "        lengthscales=1.0,\n",
    "        variance=0.1,\n",
    "        active_dims=list(range(input_dim))\n",
    "    )\n",
    "\n",
    "    coregion_kernel = gpflow.kernels.Coregion(\n",
    "        output_dim=D,\n",
    "        rank=D,\n",
    "        active_dims=[input_dim]\n",
    "    )\n",
    "\n",
    "    gpflow.utilities.set_trainable(coregion_kernel.kappa, False)\n",
    "    coregion_kernel.kappa.assign(tf.ones_like(coregion_kernel.kappa) * 1e-6)\n",
    "\n",
    "    kernel = base_kernel * coregion_kernel\n",
    "\n",
    "    model_gpr = gpflow.models.GPR(\n",
    "        data=(X_multi_train, Y_multi_train),\n",
    "        kernel=kernel,\n",
    "        mean_function=None\n",
    "    )\n",
    "\n",
    "    gpflow.utilities.set_trainable(base_kernel.variance, False)\n",
    "\n",
    "    opt = Scipy()\n",
    "\n",
    "    def objective_closure_gpr():\n",
    "        return -model_gpr.log_marginal_likelihood()\n",
    "    try:\n",
    "        opt.minimize(objective_closure_gpr, model_gpr.trainable_variables, options=dict(maxiter=1000))\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        print(\"Try reducing maxiter or checking data shapes\")\n",
    "\n",
    "    mean_pred_mogp, var_pred_mogp = model_gpr.predict_y(X_multi_test)\n",
    "    mu_mogp, std_mogp = mean_pred_mogp.numpy().reshape(-1, D, order='F'), np.sqrt(var_pred_mogp.numpy()).reshape(-1, D, order='F')\n",
    "\n",
    "    end_total = time.time()\n",
    "    time_mogp = end_total - start_total\n",
    "\n",
    "    rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp.reshape(-1, D, order='F'))\n",
    "    nlpd_mogp = nlpd(Y_test_scaled, mu_mogp.reshape(-1, D, order='F'), std_mogp.reshape(-1, D, order='F')**2)\n",
    "    \n",
    "    return rmse_mogp, nlpd_mogp, time_mogp\n",
    "\n",
    "\n",
    "def run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers, k=1):\n",
    "    start_total = time.time()\n",
    "\n",
    "    mcd = MinCovDet(support_fraction=1-prop_outliers).fit(Y_train_scaled)\n",
    "    robust_covariance = mcd.covariance_\n",
    "    robust_init_A = np.linalg.cholesky(robust_covariance)\n",
    "\n",
    "    morcgp = MORCGP_shared_noise(mean=0, length_scale=1, noise_var=0.1, A=robust_init_A)\n",
    "    morcgp.fit(X_train_scaled, Y_train_scaled, epsilons=np.array([prop_outliers, 0]))\n",
    "    morcgp.optimize_loo_cv(print_opt_param=False, print_iter_objective=False, k=k, init_cov=robust_covariance, fix_weights=True)\n",
    "\n",
    "    mu_morcgp, var_morcgp = morcgp.predict(X_test_scaled)\n",
    "    std_morcgp = np.sqrt(var_morcgp + morcgp.noise_var)\n",
    "    end_total = time.time()\n",
    "\n",
    "    time_morcgp = end_total - start_total\n",
    "    rmse_morcgp = calculate_rmse(Y_test_scaled, mu_morcgp)\n",
    "    nlpd_morcgp = nlpd(Y_test_scaled, mu_morcgp, std_morcgp**2)\n",
    "\n",
    "    return rmse_morcgp, nlpd_morcgp, time_morcgp\n",
    "\n",
    "def run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df):\n",
    "\n",
    "    X_multi_train = make_X_multi(X_train_scaled, D=2)\n",
    "    X_multi_test = make_X_multi(X_test_scaled, D=2)\n",
    "    Y_multi_train = Y_train_scaled.reshape(-1, 1, order='F')\n",
    "    Y_multi_test = Y_test_scaled.reshape(-1, 1, order='F')\n",
    "\n",
    "    input_dim = X_train_scaled.shape[1]  \n",
    "    N = X_train_scaled.shape[0]\n",
    "    D = 2\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    base_kernel = gpflow.kernels.RBF(\n",
    "        lengthscales=1.0, \n",
    "        variance=0.1, \n",
    "        active_dims=list(range(input_dim)) ,\n",
    "    )\n",
    "\n",
    "    coregion_kernel = gpflow.kernels.Coregion(\n",
    "        output_dim=D, \n",
    "        rank=D, \n",
    "        active_dims=[input_dim]  \n",
    "    )\n",
    "\n",
    "    gpflow.utilities.set_trainable(base_kernel.variance, False)\n",
    "\n",
    "    gpflow.utilities.set_trainable(coregion_kernel.kappa, False)\n",
    "    coregion_kernel.kappa.assign(tf.ones_like(coregion_kernel.kappa) * 1e-6)\n",
    "\n",
    "    kernel = base_kernel * coregion_kernel\n",
    "\n",
    "    likelihood_vgp = gpflow.likelihoods.StudentT(df=df)\n",
    "    model_vgp = gpflow.models.VGP(\n",
    "        data=(X_multi_train, Y_multi_train),\n",
    "        kernel=kernel,\n",
    "        likelihood=likelihood_vgp\n",
    "    )\n",
    "\n",
    "    opt = Scipy()\n",
    "    def objective_closure_vgp():\n",
    "        return -model_vgp.maximum_log_likelihood_objective()\n",
    "\n",
    "    try:\n",
    "        opt.minimize(objective_closure_vgp, model_vgp.trainable_variables, options=dict(maxiter=1000))\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        print(\"Try reducing maxiter or checking data shapes\")\n",
    "\n",
    "    mean_pred_tmogp, var_pred_tmogp = model_vgp.predict_y(X_multi_test)\n",
    "    mu_tmogp, std_tmogp = mean_pred_tmogp.numpy().reshape(-1, D, order='F'), np.sqrt(var_pred_tmogp.numpy()).reshape(-1, D, order='F')\n",
    "    end_total = time.time()\n",
    "\n",
    "    time_tmogp = end_total - start_total\n",
    "    rmse_tmogp = calculate_rmse(Y_test_scaled, mu_tmogp.reshape(-1, D, order='F'))\n",
    "    nlpd_tmogp = nlpd(Y_test_scaled, mu_tmogp.reshape(-1, D, order='F'), std_tmogp.reshape(-1, D, order='F')**2)\n",
    "    \n",
    "    return rmse_tmogp, nlpd_tmogp, time_tmogp\n",
    "\n",
    "def run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers):\n",
    "\n",
    "    start_total = time.time()\n",
    "\n",
    "    mcd = MinCovDet(support_fraction=1-prop_outliers).fit(Y_train_scaled)\n",
    "    robust_covariance = mcd.covariance_\n",
    "    robust_init_A = np.linalg.cholesky(robust_covariance)\n",
    "\n",
    "    mogp = MOGPRegressor_NC(mean = 0, length_scale=1, noise = 0.1, A=robust_init_A)\n",
    "    mogp.fit(X_train_scaled, Y_train_scaled)\n",
    "    mogp.optimize_hyperparameters()\n",
    "\n",
    "    mu_mogp, var_mogp = mogp.predict(X_test_scaled)\n",
    "    std_mogp = np.sqrt(var_mogp + mogp.noise)\n",
    "    end_total = time.time()\n",
    "\n",
    "    time_mogp = end_total - start_total\n",
    "    rmse_mogp = calculate_rmse(Y_test_scaled, mu_mogp)\n",
    "    nlpd_mogp = nlpd(Y_test_scaled, mu_mogp, std_mogp**2)\n",
    "\n",
    "    return rmse_mogp, nlpd_mogp, time_mogp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8674a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'\n",
    "df = pd.read_excel(url)\n",
    "X = df.loc[:, 'X1':'X8'].to_numpy()\n",
    "Y = df.loc[:, ['Y1', 'Y2']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4b9d3",
   "metadata": {},
   "source": [
    "# No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af867311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [08:24<33:39, 504.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers: t-MOGP seed 0: RMSE = 0.146973007360796, NLPD = -0.4944065429833939, Time = 504.7147419452667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [14:45<21:35, 431.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers: t-MOGP seed 1: RMSE = 0.1749226049068073, NLPD = -0.34266213419444497, Time = 380.71360754966736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [21:10<13:40, 410.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers: t-MOGP seed 2: RMSE = 0.15728139369440064, NLPD = -0.4434016445030547, Time = 384.6717734336853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [27:17<06:33, 393.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers: t-MOGP seed 3: RMSE = 0.15658368770702166, NLPD = -0.4155513952270041, Time = 366.74528765678406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [33:26<00:00, 401.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers: t-MOGP seed 4: RMSE = 0.13415408735207623, NLPD = -0.5594525046166671, Time = 369.2082133293152\n",
      "RMSE: 0.1470, 0.1749, 0.1573, 0.1566, 0.1342\n",
      "NLPD: -0.4944, -0.3427, -0.4434, -0.4156, -0.5595\n",
      "Time: 504.7147, 380.7136, 384.6718, 366.7453, 369.2082\n",
      "RMSE t-MOGP: 0.1540 ± 0.0134\n",
      "NLPD t-MOGP: -0.4511 ± 0.0731\n",
      "Time t-MOGP: 401.2107 ± 52.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0\n",
    "num_seeds = 5\n",
    "\n",
    "run_mogp = False\n",
    "run_morcgp = False\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers)\n",
    "        print(f'No outliers: MOGP seed {i}: RMSE = {rmse_mogp}, NLPD = {nlpd_mogp}, Time = {time_mogp}')\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        print(f'No outliers: MORCGP seed {i}: RMSE = {rmse_morcgp}, NLPD = {nlpd_morcgp}, Time = {time_morcgp}')\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=3)\n",
    "        print(f'No outliers: t-MOGP seed {i}: RMSE = {rmse_tmogp}, NLPD = {nlpd_tmogp}, Time = {time_tmogp}')\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_mogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_mogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_mogp))\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_morcgp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_morcgp))\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_tmogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_tmogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_tmogp))\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d493a",
   "metadata": {},
   "source": [
    "# Uniform outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b21f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:00<24:02, 360.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 0: RMSE = 0.1572463942604103, NLPD = -0.20455796440091867, Time = 360.70440769195557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [14:00<21:31, 430.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 1: RMSE = 0.17991925833265834, NLPD = -0.17016693535606028, Time = 479.40863513946533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [22:25<15:29, 464.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 2: RMSE = 0.1669034893230997, NLPD = -0.19784887675034687, Time = 505.3626959323883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [30:49<08:00, 480.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 3: RMSE = 0.15697111695479155, NLPD = -0.19714337537932117, Time = 503.55842781066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [39:03<00:00, 468.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 4: RMSE = 0.1442470571186682, NLPD = -0.23718617108509257, Time = 494.53677320480347\n",
      "RMSE: 0.1572, 0.1799, 0.1669, 0.1570, 0.1442\n",
      "NLPD: -0.2046, -0.1702, -0.1978, -0.1971, -0.2372\n",
      "Time: 360.7044, 479.4086, 505.3627, 503.5584, 494.5368\n",
      "RMSE t-MOGP: 0.1611 ± 0.0119\n",
      "NLPD t-MOGP: -0.2014 ± 0.0214\n",
      "Time t-MOGP: 468.7142 ± 54.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [08:25<33:41, 505.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 0: RMSE = 0.15992955983438906, NLPD = -0.19319021121175053, Time = 505.36597537994385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [1:26:44<2:28:37, 2972.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 1: RMSE = 0.1922459850373418, NLPD = -0.11268911455071316, Time = 4699.519051074982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:35:34<1:01:54, 1857.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform outliers: t-MOGP seed 2: RMSE = 0.1694453326731492, NLPD = -0.19436997556367355, Time = 530.0334632396698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:41:17<1:07:31, 2025.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m     times_morcgp.append(time_morcgp)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_tmogp:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rmse_tmogp, nlpd_tmogp, time_tmogp = \u001b[43mrun_tMOGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUniform outliers: t-MOGP seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: RMSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_tmogp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, NLPD = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnlpd_tmogp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_tmogp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     43\u001b[39m     rmses_tmogp.append(rmse_tmogp)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 140\u001b[39m, in \u001b[36mrun_tMOGP\u001b[39m\u001b[34m(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df)\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -model_vgp.maximum_log_likelihood_objective()\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_closure_vgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_vgp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimization failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpflow\\optimizers\\scipy.py:159\u001b[39m, in \u001b[36mScipy.minimize\u001b[39m\u001b[34m(self, closure, variables, method, step_callback, compile, allow_unused_variables, tf_fun_args, track_loss_history, **scipy_kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m     callback = \u001b[38;5;28mself\u001b[39m.loss_history_callback_func(func, history, scipy_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    157\u001b[39m     scipy_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m] = callback\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m opt_result = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscipy_kwargs\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m track_loss_history:\n\u001b[32m    164\u001b[39m     opt_result[\u001b[33m\"\u001b[39m\u001b[33mloss_history\u001b[39m\u001b[33m\"\u001b[39m] = history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:785\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    782\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    783\u001b[39m                              **options)\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    788\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    789\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:459\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    453\u001b[39m n_iterations = \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    456\u001b[39m     \u001b[38;5;66;03m# g may become float32 if a user provides a function that calculates\u001b[39;00m\n\u001b[32m    457\u001b[39m     \u001b[38;5;66;03m# the Jacobian in float32 (see gh-18730). The underlying code expects\u001b[39;00m\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# float64, so upcast it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     g = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[39;00m\n\u001b[32m    461\u001b[39m     _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                    iwa, task, lsave, isave, dsave, maxls, ln_task)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 7, 10, 20]:\n",
    "    rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "    nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "    times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "    prop_outliers = 0.1\n",
    "    num_seeds = 5\n",
    "\n",
    "    run_mogp = False\n",
    "    run_morcgp = False\n",
    "    run_tmogp = True\n",
    "\n",
    "    for i in tqdm(range(num_seeds)):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.25, random_state=i\n",
    "        )\n",
    "\n",
    "        scaler_X = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "        scaler_Y = StandardScaler()\n",
    "        Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "        Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "        Y_train_scaled = uniform_outliers_c1(Y=Y_train_scaled, percent_outliers=prop_outliers, start=6, end=9)\n",
    "\n",
    "        if run_mogp:\n",
    "            rmse_mogp, nlpd_mogp, time_mogp = run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers)\n",
    "            print(f'Uniform outliers: MOGP seed {i}: RMSE = {rmse_mogp}, NLPD = {nlpd_mogp}, Time = {time_mogp}')\n",
    "            rmses_mogp.append(rmse_mogp)\n",
    "            nlpds_mogp.append(nlpd_mogp)\n",
    "            times_mogp.append(time_mogp)\n",
    "        if run_morcgp:\n",
    "            rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "            print(f'Uniform outliers: MORCGP seed {i}: RMSE = {rmse_morcgp}, NLPD = {nlpd_morcgp}, Time = {time_morcgp}')\n",
    "            rmses_morcgp.append(rmse_morcgp)\n",
    "            nlpds_morcgp.append(nlpd_morcgp)\n",
    "            times_morcgp.append(time_morcgp)\n",
    "        if run_tmogp:\n",
    "            rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "            print(f'Uniform outliers: t-MOGP seed {i}: RMSE = {rmse_tmogp}, NLPD = {nlpd_tmogp}, Time = {time_tmogp}')\n",
    "            rmses_tmogp.append(rmse_tmogp)\n",
    "            nlpds_tmogp.append(nlpd_tmogp)\n",
    "            times_tmogp.append(time_tmogp)\n",
    "\n",
    "    if run_mogp:\n",
    "        print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_mogp))\n",
    "        print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_mogp))\n",
    "        print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_mogp))\n",
    "        print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "        print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "        print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "    if run_morcgp:\n",
    "        print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "        print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "        print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "        print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "        print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "        print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "    if run_tmogp:\n",
    "        print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_tmogp))\n",
    "        print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_tmogp))\n",
    "        print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_tmogp))\n",
    "        print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "        print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "        print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66bed1",
   "metadata": {},
   "source": [
    "# Asymmetric outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e796e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:41<13:02, 41.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 0: RMSE = 1.2263304750818784, NLPD = 1.4241092177249548, Time = 41.186551094055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:33<14:21, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 1: RMSE = 1.3671313238587208, NLPD = 1.5070556858763287, Time = 52.54415678977966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:08<11:49, 41.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 2: RMSE = 1.4691347341531134, NLPD = 1.413208861417657, Time = 34.41991186141968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:39<10:02, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 3: RMSE = 1.3759198351403035, NLPD = 1.4767989885422679, Time = 31.471731901168823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:13<09:06, 36.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 4: RMSE = 1.413511846483041, NLPD = 1.3941671399386515, Time = 34.118016958236694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:48<08:19, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 5: RMSE = 1.5095614868096416, NLPD = 1.424981909022705, Time = 34.35385990142822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:53<09:50, 45.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 6: RMSE = 1.5882524603719121, NLPD = 1.4602719403627369, Time = 65.41194748878479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [06:51<13:42, 68.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 7: RMSE = 1.418548116662246, NLPD = 1.4155042886308389, Time = 117.98744225502014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [07:26<10:38, 58.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 8: RMSE = 1.720852882680438, NLPD = 1.54773064178931, Time = 35.11240482330322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [08:08<08:51, 53.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 9: RMSE = 2.4971271264197243, NLPD = 1.8834713311668125, Time = 42.05739784240723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:42<07:06, 47.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 10: RMSE = 1.3529576762340025, NLPD = 1.404495382087161, Time = 34.186811208724976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [09:10<05:31, 41.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 11: RMSE = 1.3290237902395738, NLPD = 1.429177877546348, Time = 27.77490210533142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:45<04:35, 39.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 12: RMSE = 1.5077874022866995, NLPD = 1.4251481400137234, Time = 34.4795503616333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [10:18<03:45, 37.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 13: RMSE = 1.6372834477588385, NLPD = 1.4469731892653332, Time = 33.713326930999756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [10:53<03:03, 36.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 14: RMSE = 1.3879049970753672, NLPD = 1.4208886352570538, Time = 34.74819231033325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [11:26<02:22, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 15: RMSE = 1.301777016479256, NLPD = 1.42879556948594, Time = 32.832592248916626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:00<01:45, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 16: RMSE = 1.5055266235516216, NLPD = 1.448395123041787, Time = 33.80563950538635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [12:28<01:05, 32.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 17: RMSE = 1.6825416372176636, NLPD = 1.4949157206228854, Time = 27.756648778915405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [13:03<00:33, 33.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 18: RMSE = 1.6052106791445426, NLPD = 1.4822330993416888, Time = 35.07787466049194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:36<00:00, 40.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric outliers: MOGP seed 19: RMSE = 1.6201740302052063, NLPD = 1.4872963932345176, Time = 33.575167417526245\n",
      "RMSE: 1.2263, 1.3671, 1.4691, 1.3759, 1.4135, 1.5096, 1.5883, 1.4185, 1.7209, 2.4971, 1.3530, 1.3290, 1.5078, 1.6373, 1.3879, 1.3018, 1.5055, 1.6825, 1.6052, 1.6202\n",
      "NLPD: 1.4241, 1.5071, 1.4132, 1.4768, 1.3942, 1.4250, 1.4603, 1.4155, 1.5477, 1.8835, 1.4045, 1.4292, 1.4251, 1.4470, 1.4209, 1.4288, 1.4484, 1.4949, 1.4822, 1.4873\n",
      "Time: 41.1866, 52.5442, 34.4199, 31.4717, 34.1180, 34.3539, 65.4119, 117.9874, 35.1124, 42.0574, 34.1868, 27.7749, 34.4796, 33.7133, 34.7482, 32.8326, 33.8056, 27.7566, 35.0779, 33.5752\n",
      "RMSE MOGP: 1.5258 ± 0.2589\n",
      "NLPD MOGP: 1.4708 ± 0.1022\n",
      "Time MOGP: 40.8307 ± 19.5668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 20\n",
    "\n",
    "run_mogp = True\n",
    "run_morcgp = True\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "    np.random.seed(i)\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    Y_train_scaled = asymmetric_outliers_c1(Y=Y_train_scaled, percent_outliers=prop_outliers, start=6, end=9)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers)\n",
    "        print(f'Asymmetric outliers: MOGP seed {i}: RMSE = {rmse_mogp}, NLPD = {nlpd_mogp}, Time = {time_mogp}')\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        print(f'Asymmetric outliers: MORCGP seed {i}: RMSE = {rmse_morcgp}, NLPD = {nlpd_morcgp}, Time = {time_morcgp}')\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=10)\n",
    "        print(f'Asymmetric outliers: t-MOGP seed {i}: RMSE = {rmse_tmogp}, NLPD = {nlpd_tmogp}, Time = {time_tmogp}')\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_mogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_mogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_mogp))\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_morcgp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_morcgp))\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_tmogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_tmogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_tmogp))\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24022cf5",
   "metadata": {},
   "source": [
    "# Focused outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac57997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:29<25:58, 389.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused outliers: t-MOGP seed 0: RMSE = 0.1536962317708841, NLPD = -0.2889329853521784, Time = 389.48088479042053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:56<19:23, 387.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused outliers: t-MOGP seed 1: RMSE = 0.17260855747850806, NLPD = -0.24833868379034593, Time = 386.43613600730896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [19:39<13:09, 394.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused outliers: t-MOGP seed 2: RMSE = 0.15863754813258865, NLPD = -0.30404632338029386, Time = 402.98646092414856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [26:02<06:30, 390.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused outliers: t-MOGP seed 3: RMSE = 0.1545796345326007, NLPD = -0.30688950709599677, Time = 383.6019196510315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [32:03<00:00, 384.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused outliers: t-MOGP seed 4: RMSE = 0.1372621573364756, NLPD = -0.32848423373834557, Time = 360.2018735408783\n",
      "RMSE: 0.1537, 0.1726, 0.1586, 0.1546, 0.1373\n",
      "NLPD: -0.2889, -0.2483, -0.3040, -0.3069, -0.3285\n",
      "Time: 389.4809, 386.4361, 402.9865, 383.6019, 360.2019\n",
      "RMSE t-MOGP: 0.1554 ± 0.0113\n",
      "NLPD t-MOGP: -0.2953 ± 0.0267\n",
      "Time t-MOGP: 384.5415 ± 13.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 5\n",
    "\n",
    "run_mogp = False\n",
    "run_morcgp = False\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    X_train_scaled, Y_train_scaled = focused_outliers_c1(X=X_train_scaled, Y=Y_train_scaled, percent_outliers=prop_outliers, y_value=6, perturbation=0.1)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers)\n",
    "        print(f'Focused outliers: MOGP seed {i}: RMSE = {rmse_mogp}, NLPD = {nlpd_mogp}, Time = {time_mogp}')\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        print(f'Focused outliers: MORCGP seed {i}: RMSE = {rmse_morcgp}, NLPD = {nlpd_morcgp}, Time = {time_morcgp}')\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=3)\n",
    "        print(f'Focused outliers: t-MOGP seed {i}: RMSE = {rmse_tmogp}, NLPD = {nlpd_tmogp}, Time = {time_tmogp}')\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_mogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_mogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_mogp))\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_morcgp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_morcgp))\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_tmogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_tmogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_tmogp))\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0d678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogp_none = [158.0034, 116.2615, 105.6857, 116.5271, 34.6130, 43.0605, 66.9163, 116.1803, 88.1225, 78.9245, 56.6967, 35.8389, 37.9026, 28.4682, 43.0024, 69.6120, 149.4625, 140.7788, 127.7312, 94.4481]\n",
    "mogp_uniform = [32.8033, 35.7605, 30.9526, 34.4374, 34.4876, 34.3665, 34.5291, 34.3960, 34.3017, 35.8013, 34.3950, 34.1281, 30.7224, 30.6244, 34.0911, 47.3710, 46.1654, 115.5118, 82.1745, 31.9227]\n",
    "mogp_asymmetric = [41.1866, 52.5442, 34.4199, 31.4717, 34.1180, 34.3539, 65.4119, 117.9874, 35.1124, 42.0574, 34.1868, 27.7749, 34.4796, 33.7133, 34.7482, 32.8326, 33.8056, 27.7566, 35.0779, 33.5752]\n",
    "mogp_focused = [42.4002, 31.1451, 30.7974, 78.5144, 33.5454, 21.8565, 57.5175, 61.4166, 21.1836, 28.0592, 21.3794, 91.0886, 75.2422, 63.2028, 21.8592, 30.9643, 51.9118, 73.3811, 75.7829, 42.6316]\n",
    "\n",
    "\n",
    "morcgp_none = [77.8224, 43.2904, 19.1723, 27.3977, 54.7897, 45.4805, 36.2380, 19.1061, 37.6373, 28.3980, 52.6968, 46.4609, 35.7727, 46.9938, 80.4785, 50.5067, 86.4893, 36.1651, 18.8809, 32.2453]\n",
    "morcgp_uniform = [0.1552, 0.1536, 0.1598, 0.1541, 0.1384, 0.1544, 0.1566, 0.1844, 0.1399, 0.1774, 0.1345, 0.1520, 0.1695, 0.1944, 0.1453, 0.2432, 0.1492, 0.1418, 0.1618, 0.1666]\n",
    "morcgp_asymmetric = [27.1474, 16.5053, 24.9797, 26.1462, 133.2675, 69.7731, 34.9839, 75.4082, 94.8574, 27.1894, 18.2282, 22.5180, 26.8613, 35.6525, 73.1197, 31.1423, 22.6991, 30.6604, 20.8860, 100.6261]\n",
    "morcgp_focused = [119.3804, 209.0515, 39.3439, 59.4625, 92.8787, 74.0522, 73.2045, 184.7929, 39.2562, 80.5925, 168.6580, 153.2525, 170.7675, 140.7253, 145.0415, 44.9886, 36.9084, 50.7111, 113.2678, 43.8412]\n",
    "\n",
    "\n",
    "tmogp_none = [327.9552, 355.3528, 338.7198, 336.3116, 334.5649, 332.6714, 328.9937, 330.0461, 330.1724, 331.1063, 330.8402, 333.3201, 337.0568, 330.9253, 344.7965, 329.6715, 326.3163, 330.2525, 339.9834, 331.3912]\n",
    "tmogp_uniform = [319.2671, 325.2557, 338.7163, 334.1679, 333.0068, 337.2833, 334.3017, 331.7658, 336.9343, 336.8160, 332.0768, 326.3337, 336.8017, 333.6870, 335.5295, 331.0837, 330.6503, 332.3806, 339.5021, 339.0016]\n",
    "tmogp_asymmetric = [326.6452, 333.1712, 338.1042, 336.1134, 333.4772, 338.9957, 336.9769, 341.0775, 331.8895, 338.2517, 334.5576, 329.4912, 339.1115, 333.9206, 331.4695, 330.8334, 325.1819, 332.3735, 339.1843, 330.3473]\n",
    "tmogp_focused = [331.5940, 335.6956, 335.8170, 334.5840, 327.1402, 334.3425, 336.6477, 326.4879, 341.8681, 327.1014, 323.8503, 335.1000, 340.7597, 147.1594, 331.8168, 332.2173, 330.1042, 328.6798, 325.0340, 341.2398]\n",
    "\n",
    "\n",
    "mogp_all = mogp_none + mogp_uniform + mogp_asymmetric + mogp_focused\n",
    "morcgp_all = morcgp_none + morcgp_uniform + morcgp_asymmetric + morcgp_focused\n",
    "tmogp_all = tmogp_none + tmogp_uniform + tmogp_asymmetric + tmogp_focused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc0524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Combine lists into a list of lists\n",
    "data = [mogp_all, morcgp_all, tmogp_all]\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom colors in required order\n",
    "colors = [\"green\", \"royalblue\", \"orange\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Thicker axes borders\n",
    "plt.gca().spines[\"top\"].set_linewidth(2)\n",
    "plt.gca().spines[\"right\"].set_linewidth(2)\n",
    "plt.gca().spines[\"left\"].set_linewidth(2)\n",
    "plt.gca().spines[\"bottom\"].set_linewidth(2)\n",
    "\n",
    "# Boxplot with thick borders\n",
    "sns.boxplot(\n",
    "    data=data,\n",
    "    palette=colors,\n",
    "    linewidth=1.8,            # thicker box borders\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "# Labels\n",
    "plt.xticks([0, 1, 2], [r'MOGP', r'MO-RCGP', r'$t$-MOGP'])\n",
    "plt.ylabel(r'Runtime (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fa22669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# RMSE values extracted from your table\n",
    "outlier_types = [\"None\", \"Uniform\", \"Asymmetric\"]\n",
    "\n",
    "rmse_MOGP     = [0.12, 1.39, 1.53]\n",
    "rmse_MORCGP   = [0.12, 0.16, 0.17]\n",
    "rmse_tMOGP    = [0.14, 0.16, 0.16]\n",
    "\n",
    "x = np.arange(len(outlier_types))\n",
    "width = 0.15  # width of each bar\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Make the figure border thicker\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Bars with outlines\n",
    "ax.bar(x - width, rmse_MOGP,    width, label=\"MOGP\",\n",
    "       color='green', edgecolor='black', linewidth=1.3)\n",
    "ax.bar(x,         rmse_MORCGP,  width, label=\"MO-RCGP\",\n",
    "       color='royalblue', edgecolor='black', linewidth=1.3)\n",
    "ax.bar(x + width, rmse_tMOGP,   width, label=r\"$t$-MOGP\",\n",
    "       color='orange', edgecolor='black', linewidth=1.3)\n",
    "\n",
    "# Labels & formatting\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "# ax.set_title(\"RMSE by Method and Outlier Type\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(outlier_types)\n",
    "\n",
    "# Legend below the plot\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=3, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13125090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326.47248 329.63544 330.83816 331.7964  333.089   334.42854 336.17286\n",
      " 337.44748 339.21608]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decile_quantiles(values):\n",
    "    \"\"\"\n",
    "    Returns the 10%, 20%, ..., 90% quantiles of a list of numbers.\n",
    "    \"\"\"\n",
    "    probs = np.arange(0.1, 1.0, 0.1)  # 0.1, 0.2, ..., 0.9\n",
    "    return np.quantile(values, probs)\n",
    "# print(decile_quantiles(mogp_all))\n",
    "# print(decile_quantiles(morcgp_all))\n",
    "print(decile_quantiles(tmogp_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4a18e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.134500', '0.145125', '12.439775', '35.712600', '73.140900', '154.022775', '209.051500']\n",
      "['147.159400', '325.174505', '330.232475', '333.089000', '336.845575', '341.085615', '355.352800']\n"
     ]
    }
   ],
   "source": [
    "def boxplot_values(values):\n",
    "    probs = np.array([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "    minimum = np.min(values)\n",
    "    maximum = np.max(values)\n",
    "    arr = [minimum] + list(np.quantile(values, probs)) + [maximum]\n",
    "    return [f\"{x:.6f}\" for x in arr]\n",
    "# print(boxplot_values(mogp_all))\n",
    "print(boxplot_values(morcgp_all))\n",
    "print(boxplot_values(tmogp_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb697e",
   "metadata": {},
   "source": [
    "# Student-t outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:25<25:43, 385.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-t outliers: t-MOGP seed 0: RMSE = 0.1467389110638898, NLPD = -0.4381454820961423, Time = 385.83802556991577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:30<18:40, 373.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-t outliers: t-MOGP seed 1: RMSE = 0.17191644676947804, NLPD = -0.3194124634763358, Time = 364.56728315353394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [18:37<12:21, 370.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-t outliers: t-MOGP seed 2: RMSE = 0.15574287467677875, NLPD = -0.41419876708980263, Time = 366.9639685153961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [26:13<06:44, 404.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-t outliers: t-MOGP seed 3: RMSE = 0.1450338947335473, NLPD = -0.4310896245107469, Time = 455.4786260128021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [34:50<00:00, 418.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student-t outliers: t-MOGP seed 4: RMSE = 0.13605355065955416, NLPD = -0.4867451519818098, Time = 517.1459333896637\n",
      "RMSE: 0.1467, 0.1719, 0.1557, 0.1450, 0.1361\n",
      "NLPD: -0.4381, -0.3194, -0.4142, -0.4311, -0.4867\n",
      "Time: 385.8380, 364.5673, 366.9640, 455.4786, 517.1459\n",
      "RMSE t-MOGP: 0.1511 ± 0.0121\n",
      "NLPD t-MOGP: -0.4179 ± 0.0548\n",
      "Time t-MOGP: 417.9988 ± 59.5461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses_mogp, rmses_morcgp, rmses_tmogp = [], [], []\n",
    "nlpds_mogp, nlpds_morcgp, nlpds_tmogp = [], [], []\n",
    "times_mogp, times_morcgp, times_tmogp = [], [], []\n",
    "\n",
    "prop_outliers = 0.1\n",
    "num_seeds = 5\n",
    "\n",
    "run_mogp = False\n",
    "run_morcgp = False\n",
    "run_tmogp = True\n",
    "\n",
    "for i in tqdm(range(num_seeds)):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=i\n",
    "    )\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    scaler_Y = StandardScaler()\n",
    "    Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "    Y_test_scaled = scaler_Y.transform(Y_test)\n",
    "\n",
    "    Y_train_scaled = student_t_outliers(Y=Y_train_scaled, percent_outliers=prop_outliers, df=5, scale=1.0)\n",
    "\n",
    "    if run_mogp:\n",
    "        rmse_mogp, nlpd_mogp, time_mogp = run_MOGP_numpy(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers)\n",
    "        print(f'Student-t outliers: MOGP seed {i}: RMSE = {rmse_mogp}, NLPD = {nlpd_mogp}, Time = {time_mogp}')\n",
    "        rmses_mogp.append(rmse_mogp)\n",
    "        nlpds_mogp.append(nlpd_mogp)\n",
    "        times_mogp.append(time_mogp)\n",
    "    if run_morcgp:\n",
    "        rmse_morcgp, nlpd_morcgp, time_morcgp = run_MORCGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, prop_outliers=prop_outliers, k=2)\n",
    "        print(f'Student-t outliers: MORCGP seed {i}: RMSE = {rmse_morcgp}, NLPD = {nlpd_morcgp}, Time = {time_morcgp}')\n",
    "        rmses_morcgp.append(rmse_morcgp)\n",
    "        nlpds_morcgp.append(nlpd_morcgp)\n",
    "        times_morcgp.append(time_morcgp)\n",
    "    if run_tmogp:\n",
    "        rmse_tmogp, nlpd_tmogp, time_tmogp = run_tMOGP(X_train_scaled, Y_train_scaled, X_test_scaled, Y_test_scaled, df=3)\n",
    "        print(f'Student-t outliers: t-MOGP seed {i}: RMSE = {rmse_tmogp}, NLPD = {nlpd_tmogp}, Time = {time_tmogp}')\n",
    "        rmses_tmogp.append(rmse_tmogp)\n",
    "        nlpds_tmogp.append(nlpd_tmogp)\n",
    "        times_tmogp.append(time_tmogp)\n",
    "\n",
    "if run_mogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_mogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_mogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_mogp))\n",
    "    print(f'RMSE MOGP: {np.mean(rmses_mogp):.4f} ± {np.std(rmses_mogp):.4f}')\n",
    "    print(f'NLPD MOGP: {np.mean(nlpds_mogp):.4f} ± {np.std(nlpds_mogp):.4f}')\n",
    "    print(f'Time MOGP: {np.mean(times_mogp):.4f} ± {np.std(times_mogp):.4f}')\n",
    "\n",
    "if run_morcgp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in rmses_morcgp))\n",
    "    print(f'RMSE MORCGP: {np.mean(rmses_morcgp):.4f} ± {np.std(rmses_morcgp):.4f}')\n",
    "    print(f'NLPD MORCGP: {np.mean(nlpds_morcgp):.4f} ± {np.std(nlpds_morcgp):.4f}')\n",
    "    print(f'Time MORCGP: {np.mean(times_morcgp):.4f} ± {np.std(times_morcgp):.4f}')\n",
    "\n",
    "if run_tmogp:\n",
    "    print(\"RMSE:\", \", \".join(f\"{x:.4f}\" for x in rmses_tmogp))\n",
    "    print(\"NLPD:\", \", \".join(f\"{x:.4f}\" for x in nlpds_tmogp))\n",
    "    print(\"Time:\", \", \".join(f\"{x:.4f}\" for x in times_tmogp))\n",
    "    print(f'RMSE t-MOGP: {np.mean(rmses_tmogp):.4f} ± {np.std(rmses_tmogp):.4f}')\n",
    "    print(f'NLPD t-MOGP: {np.mean(nlpds_tmogp):.4f} ± {np.std(nlpds_tmogp):.4f}')\n",
    "    print(f'Time t-MOGP: {np.mean(times_tmogp):.4f} ± {np.std(times_tmogp):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
